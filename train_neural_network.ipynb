{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc2fc48f-dbcc-4e6c-bc0e-8d1e72e670a4",
   "metadata": {},
   "source": [
    "# Salary Prediction from LinkedIn Job Postings - Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3375fb27-0be7-4da8-9378-9137587226e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nginyc/repos/job_posting_salary_prediction/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import salary\n",
    "import seaborn as sns\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, TargetEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337486df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcc83ff-8948-46b2-94bd-096093c31122",
   "metadata": {},
   "source": [
    "## Train & Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfcb495",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train) = salary.get_train_dataset()\n",
    "(X_test, y_test) = salary.get_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ea4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('one_hot_encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), ['norm_title', 'clustered_edu_req', 'clustered_pref_qual', 'clustered_req_skill', 'location_state', 'company_industries', 'formatted_experience_level', 'formatted_work_type']),\n",
    "            ('target_encoder', TargetEncoder(random_state=42), ['norm_title', 'clustered_edu_req', 'clustered_pref_qual', 'clustered_req_skill', 'location_state', 'company_industries', 'formatted_experience_level', 'formatted_work_type']),\n",
    "            ('experience_level', salary.experience_level_encoder, ['formatted_experience_level']),\n",
    "            ('work_type', salary.work_type_encoder, ['formatted_work_type']),\n",
    "            ('remote_allowed', 'passthrough', ['remote_allowed']),\n",
    "            ('company_employee_count', SimpleImputer(strategy='median'), ['company_employee_count']),\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    ),\n",
    "    StandardScaler(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec93e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    n_units_1=256,\n",
    "    n_units_2=192,\n",
    "    n_units_3=64,\n",
    "    n_units_4=32,\n",
    "    dropout_rate=0.3,\n",
    "    learning_rate=0.05,\n",
    "    optimizer_name=\"adamw\"\n",
    "):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(318,)))\n",
    "\n",
    "    # Layer 1\n",
    "    model.add(keras.layers.Dense(n_units_1, activation='leaky_relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(keras.layers.Dense(n_units_2, activation='leaky_relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    # Layer 3\n",
    "    if n_units_3:\n",
    "        model.add(keras.layers.Dense(n_units_3, activation='leaky_relu'))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    # Layer 4\n",
    "    if n_units_4:\n",
    "        model.add(keras.layers.Dense(n_units_4, activation='leaky_relu'))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(keras.layers.Dense(1))  # Output layer for regression\n",
    "\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == \"adamw\":\n",
    "        optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae', 'r2_score'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9844899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 12900023296.0000 - mae: 95258.2500 - r2_score: -2.2993 - val_loss: 8236237824.0000 - val_mae: 77363.8750 - val_r2_score: -1.1591 - learning_rate: 0.0500\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8612246528.0000 - mae: 76600.5703 - r2_score: -1.2921 - val_loss: 5254558720.0000 - val_mae: 55707.8906 - val_r2_score: -0.3775 - learning_rate: 0.0500\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4236187648.0000 - mae: 47914.9688 - r2_score: -0.1287 - val_loss: 3849106432.0000 - val_mae: 41505.1875 - val_r2_score: -0.0090 - learning_rate: 0.0500\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2904269312.0000 - mae: 33758.8984 - r2_score: 0.2763 - val_loss: 3289467136.0000 - val_mae: 30346.1152 - val_r2_score: 0.1377 - learning_rate: 0.0500\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2336294400.0000 - mae: 29640.1074 - r2_score: 0.3799 - val_loss: 3158896384.0000 - val_mae: 28853.3398 - val_r2_score: 0.1719 - learning_rate: 0.0500\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2196983808.0000 - mae: 28625.6719 - r2_score: 0.4102 - val_loss: 3679080960.0000 - val_mae: 29148.7188 - val_r2_score: 0.0355 - learning_rate: 0.0500\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2303180032.0000 - mae: 29091.7891 - r2_score: 0.4101 - val_loss: 3161312256.0000 - val_mae: 28374.3105 - val_r2_score: 0.1713 - learning_rate: 0.0500\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2210869504.0000 - mae: 28892.7285 - r2_score: 0.4228 - val_loss: 3156229120.0000 - val_mae: 29182.1250 - val_r2_score: 0.1726 - learning_rate: 0.0500\n",
      "Epoch 9/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2035358336.0000 - mae: 28221.4023 - r2_score: 0.4361 - val_loss: 3043873792.0000 - val_mae: 29093.8633 - val_r2_score: 0.2021 - learning_rate: 0.0500\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2171450880.0000 - mae: 28600.1230 - r2_score: 0.4385 - val_loss: 2315928064.0000 - val_mae: 28371.6055 - val_r2_score: 0.3929 - learning_rate: 0.0500\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2397375232.0000 - mae: 29360.4219 - r2_score: 0.4193 - val_loss: 2371149568.0000 - val_mae: 28000.2930 - val_r2_score: 0.3784 - learning_rate: 0.0500\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2204213760.0000 - mae: 28858.4355 - r2_score: 0.4447 - val_loss: 2187157248.0000 - val_mae: 29086.3672 - val_r2_score: 0.4266 - learning_rate: 0.0500\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1962403200.0000 - mae: 27996.8145 - r2_score: 0.4688 - val_loss: 2200846336.0000 - val_mae: 28526.0371 - val_r2_score: 0.4231 - learning_rate: 0.0500\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2246207232.0000 - mae: 28972.1016 - r2_score: 0.4482 - val_loss: 2194172928.0000 - val_mae: 27695.0938 - val_r2_score: 0.4248 - learning_rate: 0.0500\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1981918336.0000 - mae: 28166.8340 - r2_score: 0.4683 - val_loss: 2209224704.0000 - val_mae: 28499.8184 - val_r2_score: 0.4209 - learning_rate: 0.0500\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2091519616.0000 - mae: 28176.2949 - r2_score: 0.4558 - val_loss: 2273508352.0000 - val_mae: 28938.3418 - val_r2_score: 0.4040 - learning_rate: 0.0500\n",
      "Epoch 17/150\n",
      "\u001b[1m275/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2250146816.0000 - mae: 28986.2188 - r2_score: 0.4538\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2247480832.0000 - mae: 28979.4746 - r2_score: 0.4538 - val_loss: 2239982336.0000 - val_mae: 28048.3770 - val_r2_score: 0.4128 - learning_rate: 0.0500\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2162594048.0000 - mae: 28229.7676 - r2_score: 0.4736 - val_loss: 2197383168.0000 - val_mae: 27556.1230 - val_r2_score: 0.4240 - learning_rate: 0.0250\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1791659008.0000 - mae: 27024.9844 - r2_score: 0.5125 - val_loss: 2195606272.0000 - val_mae: 27737.6445 - val_r2_score: 0.4244 - learning_rate: 0.0250\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1900291968.0000 - mae: 27356.6621 - r2_score: 0.5119 - val_loss: 2162440192.0000 - val_mae: 27426.1113 - val_r2_score: 0.4331 - learning_rate: 0.0250\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1868515712.0000 - mae: 27297.2188 - r2_score: 0.5242 - val_loss: 2239567104.0000 - val_mae: 27726.1641 - val_r2_score: 0.4129 - learning_rate: 0.0250\n",
      "Epoch 22/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1885493376.0000 - mae: 27229.3184 - r2_score: 0.5176 - val_loss: 2182513152.0000 - val_mae: 27525.6914 - val_r2_score: 0.4279 - learning_rate: 0.0250\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1912119552.0000 - mae: 27203.1523 - r2_score: 0.5289 - val_loss: 2263489536.0000 - val_mae: 27853.5996 - val_r2_score: 0.4066 - learning_rate: 0.0250\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1876361472.0000 - mae: 27459.4121 - r2_score: 0.5075 - val_loss: 2242351872.0000 - val_mae: 27678.1074 - val_r2_score: 0.4122 - learning_rate: 0.0250\n",
      "Epoch 25/150\n",
      "\u001b[1m268/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1782265344.0000 - mae: 27036.3906 - r2_score: 0.5263\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1785123328.0000 - mae: 27048.8086 - r2_score: 0.5261 - val_loss: 2231540736.0000 - val_mae: 27595.5742 - val_r2_score: 0.4150 - learning_rate: 0.0250\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1655379968.0000 - mae: 26402.7773 - r2_score: 0.5566 - val_loss: 2188392704.0000 - val_mae: 27459.8848 - val_r2_score: 0.4263 - learning_rate: 0.0125\n",
      "Epoch 27/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1539344384.0000 - mae: 25970.3535 - r2_score: 0.5671 - val_loss: 2255487488.0000 - val_mae: 27899.3496 - val_r2_score: 0.4087 - learning_rate: 0.0125\n",
      "Epoch 28/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1655365504.0000 - mae: 26433.9844 - r2_score: 0.5646 - val_loss: 2253552896.0000 - val_mae: 27603.6992 - val_r2_score: 0.4092 - learning_rate: 0.0125\n",
      "Epoch 29/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1670002944.0000 - mae: 26232.7656 - r2_score: 0.5621 - val_loss: 2255043072.0000 - val_mae: 27529.2422 - val_r2_score: 0.4088 - learning_rate: 0.0125\n",
      "Epoch 30/150\n",
      "\u001b[1m270/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1646960256.0000 - mae: 26301.8398 - r2_score: 0.5767\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1647477120.0000 - mae: 26307.6680 - r2_score: 0.5765 - val_loss: 2271636224.0000 - val_mae: 27716.0059 - val_r2_score: 0.4045 - learning_rate: 0.0125\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 12386321408.0000 - mae: 93911.6719 - r2_score: -2.3910 - val_loss: 9174887424.0000 - val_mae: 84289.1641 - val_r2_score: -1.6016 - learning_rate: 0.0500\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8366131200.0000 - mae: 75853.5234 - r2_score: -1.3146 - val_loss: 4900855808.0000 - val_mae: 55187.1719 - val_r2_score: -0.3897 - learning_rate: 0.0500\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4027113472.0000 - mae: 47739.2539 - r2_score: -0.1601 - val_loss: 3320070912.0000 - val_mae: 40160.8477 - val_r2_score: 0.0586 - learning_rate: 0.0500\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2660984064.0000 - mae: 32862.8672 - r2_score: 0.2757 - val_loss: 2312524800.0000 - val_mae: 28882.0547 - val_r2_score: 0.3443 - learning_rate: 0.0500\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2275464704.0000 - mae: 29070.3164 - r2_score: 0.3812 - val_loss: 2608260096.0000 - val_mae: 28386.9336 - val_r2_score: 0.2604 - learning_rate: 0.0500\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2333238528.0000 - mae: 29503.2207 - r2_score: 0.3859 - val_loss: 2559547904.0000 - val_mae: 28467.9707 - val_r2_score: 0.2742 - learning_rate: 0.0500\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2122508928.0000 - mae: 28709.7285 - r2_score: 0.4138 - val_loss: 2551344128.0000 - val_mae: 28376.0195 - val_r2_score: 0.2765 - learning_rate: 0.0500\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2204795648.0000 - mae: 28726.9922 - r2_score: 0.4108 - val_loss: 2722488832.0000 - val_mae: 28356.3340 - val_r2_score: 0.2280 - learning_rate: 0.0500\n",
      "Epoch 9/150\n",
      "\u001b[1m277/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2207443712.0000 - mae: 29005.8008 - r2_score: 0.4223\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2206795008.0000 - mae: 29003.2441 - r2_score: 0.4223 - val_loss: 2402939392.0000 - val_mae: 27987.9316 - val_r2_score: 0.3186 - learning_rate: 0.0500\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1972269056.0000 - mae: 27905.6562 - r2_score: 0.4437 - val_loss: 2338738176.0000 - val_mae: 27747.5566 - val_r2_score: 0.3368 - learning_rate: 0.0250\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1990875136.0000 - mae: 27761.2344 - r2_score: 0.4545 - val_loss: 2172734464.0000 - val_mae: 27474.0879 - val_r2_score: 0.3839 - learning_rate: 0.0250\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2027716608.0000 - mae: 28005.6621 - r2_score: 0.4558 - val_loss: 2081465472.0000 - val_mae: 27515.8242 - val_r2_score: 0.4098 - learning_rate: 0.0250\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1978908288.0000 - mae: 27749.7559 - r2_score: 0.4656 - val_loss: 1956066304.0000 - val_mae: 27289.7227 - val_r2_score: 0.4453 - learning_rate: 0.0250\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2026036352.0000 - mae: 28119.2891 - r2_score: 0.4767 - val_loss: 1950755712.0000 - val_mae: 27329.8984 - val_r2_score: 0.4468 - learning_rate: 0.0250\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2139213568.0000 - mae: 28031.0176 - r2_score: 0.4641 - val_loss: 1986615552.0000 - val_mae: 27241.4531 - val_r2_score: 0.4367 - learning_rate: 0.0250\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1805986816.0000 - mae: 27011.2090 - r2_score: 0.5071 - val_loss: 2018091264.0000 - val_mae: 27457.5371 - val_r2_score: 0.4277 - learning_rate: 0.0250\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1827504384.0000 - mae: 27156.5645 - r2_score: 0.5030 - val_loss: 1945534080.0000 - val_mae: 27230.9492 - val_r2_score: 0.4483 - learning_rate: 0.0250\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1840762240.0000 - mae: 27443.7500 - r2_score: 0.5013 - val_loss: 1969910400.0000 - val_mae: 27276.5508 - val_r2_score: 0.4414 - learning_rate: 0.0250\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1936311040.0000 - mae: 27328.1973 - r2_score: 0.4973 - val_loss: 1963853184.0000 - val_mae: 27169.1387 - val_r2_score: 0.4431 - learning_rate: 0.0250\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1784764800.0000 - mae: 26734.4531 - r2_score: 0.5114 - val_loss: 1955136896.0000 - val_mae: 27121.4355 - val_r2_score: 0.4456 - learning_rate: 0.0250\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1805327360.0000 - mae: 27260.0176 - r2_score: 0.5071 - val_loss: 2013878528.0000 - val_mae: 27283.3633 - val_r2_score: 0.4289 - learning_rate: 0.0250\n",
      "Epoch 22/150\n",
      "\u001b[1m274/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1989647232.0000 - mae: 27199.5469 - r2_score: 0.5053\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1985640960.0000 - mae: 27196.7266 - r2_score: 0.5055 - val_loss: 1953872128.0000 - val_mae: 27197.5059 - val_r2_score: 0.4460 - learning_rate: 0.0250\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1798394368.0000 - mae: 26713.3691 - r2_score: 0.5306 - val_loss: 1990128896.0000 - val_mae: 27335.8203 - val_r2_score: 0.4357 - learning_rate: 0.0125\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1619680768.0000 - mae: 26196.0898 - r2_score: 0.5419 - val_loss: 1998415744.0000 - val_mae: 26998.0566 - val_r2_score: 0.4333 - learning_rate: 0.0125\n",
      "Epoch 25/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1575062656.0000 - mae: 26118.2969 - r2_score: 0.5664 - val_loss: 2024846080.0000 - val_mae: 27287.4551 - val_r2_score: 0.4258 - learning_rate: 0.0125\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1545474304.0000 - mae: 25756.9473 - r2_score: 0.5618 - val_loss: 2006943872.0000 - val_mae: 27208.6992 - val_r2_score: 0.4309 - learning_rate: 0.0125\n",
      "Epoch 27/150\n",
      "\u001b[1m271/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1740487936.0000 - mae: 26284.6797 - r2_score: 0.5712\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1735361408.0000 - mae: 26276.8945 - r2_score: 0.5712 - val_loss: 1959359104.0000 - val_mae: 27102.7207 - val_r2_score: 0.4444 - learning_rate: 0.0125\n",
      "Epoch 27: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 12805121024.0000 - mae: 95566.4531 - r2_score: -2.4098 - val_loss: 9220164608.0000 - val_mae: 83486.8203 - val_r2_score: -1.4875 - learning_rate: 0.0500\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8407835136.0000 - mae: 75949.8828 - r2_score: -1.2876 - val_loss: 5938783232.0000 - val_mae: 62732.0430 - val_r2_score: -0.6022 - learning_rate: 0.0500\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4503005184.0000 - mae: 48942.9609 - r2_score: -0.1453 - val_loss: 3538796544.0000 - val_mae: 41036.8320 - val_r2_score: 0.0453 - learning_rate: 0.0500\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2602518784.0000 - mae: 32997.2188 - r2_score: 0.2848 - val_loss: 2645548800.0000 - val_mae: 30064.8184 - val_r2_score: 0.2863 - learning_rate: 0.0500\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2477298688.0000 - mae: 29606.6816 - r2_score: 0.3728 - val_loss: 2336535040.0000 - val_mae: 28250.5254 - val_r2_score: 0.3696 - learning_rate: 0.0500\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2246935040.0000 - mae: 29023.1348 - r2_score: 0.3985 - val_loss: 2355135232.0000 - val_mae: 27685.9551 - val_r2_score: 0.3646 - learning_rate: 0.0500\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2166147328.0000 - mae: 28898.2793 - r2_score: 0.4218 - val_loss: 2341876992.0000 - val_mae: 27856.2520 - val_r2_score: 0.3682 - learning_rate: 0.0500\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2330872832.0000 - mae: 29112.5469 - r2_score: 0.4038 - val_loss: 2300899328.0000 - val_mae: 27296.6445 - val_r2_score: 0.3792 - learning_rate: 0.0500\n",
      "Epoch 9/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2107601280.0000 - mae: 28656.8301 - r2_score: 0.4293 - val_loss: 2285129728.0000 - val_mae: 27418.2480 - val_r2_score: 0.3835 - learning_rate: 0.0500\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1969039744.0000 - mae: 28246.7207 - r2_score: 0.4528 - val_loss: 2360110336.0000 - val_mae: 27543.2812 - val_r2_score: 0.3633 - learning_rate: 0.0500\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1949381120.0000 - mae: 28040.8516 - r2_score: 0.4550 - val_loss: 2300076288.0000 - val_mae: 27469.7012 - val_r2_score: 0.3795 - learning_rate: 0.0500\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2026657280.0000 - mae: 28375.2227 - r2_score: 0.4629 - val_loss: 2272908800.0000 - val_mae: 29419.5859 - val_r2_score: 0.3868 - learning_rate: 0.0500\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2037123584.0000 - mae: 28155.8164 - r2_score: 0.4667 - val_loss: 2174360064.0000 - val_mae: 27681.7285 - val_r2_score: 0.4134 - learning_rate: 0.0500\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2063690496.0000 - mae: 28505.0391 - r2_score: 0.4554 - val_loss: 2095188992.0000 - val_mae: 27192.7930 - val_r2_score: 0.4347 - learning_rate: 0.0500\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1894285312.0000 - mae: 28003.7637 - r2_score: 0.4691 - val_loss: 2142252288.0000 - val_mae: 27448.1445 - val_r2_score: 0.4220 - learning_rate: 0.0500\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1851150848.0000 - mae: 27955.0547 - r2_score: 0.4900 - val_loss: 2069511808.0000 - val_mae: 27763.8359 - val_r2_score: 0.4417 - learning_rate: 0.0500\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2057698176.0000 - mae: 28494.7227 - r2_score: 0.4760 - val_loss: 2128343552.0000 - val_mae: 27962.2559 - val_r2_score: 0.4258 - learning_rate: 0.0500\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1926195584.0000 - mae: 27527.1113 - r2_score: 0.4900 - val_loss: 2173179136.0000 - val_mae: 27729.6602 - val_r2_score: 0.4137 - learning_rate: 0.0500\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2094359424.0000 - mae: 28386.9492 - r2_score: 0.4744 - val_loss: 2132855040.0000 - val_mae: 27220.3125 - val_r2_score: 0.4246 - learning_rate: 0.0500\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1946714752.0000 - mae: 27711.1309 - r2_score: 0.4904 - val_loss: 2115264256.0000 - val_mae: 27219.3125 - val_r2_score: 0.4293 - learning_rate: 0.0500\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1824640512.0000 - mae: 27914.9707 - r2_score: 0.5148\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1824821120.0000 - mae: 27914.1074 - r2_score: 0.5147 - val_loss: 2151613184.0000 - val_mae: 27598.6250 - val_r2_score: 0.4195 - learning_rate: 0.0500\n",
      "Epoch 22/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1925937536.0000 - mae: 27819.9746 - r2_score: 0.5070 - val_loss: 2092538496.0000 - val_mae: 26878.9668 - val_r2_score: 0.4355 - learning_rate: 0.0250\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1698675968.0000 - mae: 26777.8652 - r2_score: 0.5329 - val_loss: 2073275648.0000 - val_mae: 27669.0859 - val_r2_score: 0.4407 - learning_rate: 0.0250\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1798611456.0000 - mae: 27127.1953 - r2_score: 0.5395 - val_loss: 2030624256.0000 - val_mae: 27147.4551 - val_r2_score: 0.4522 - learning_rate: 0.0250\n",
      "Epoch 25/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1633257856.0000 - mae: 26566.2090 - r2_score: 0.5601 - val_loss: 2026847104.0000 - val_mae: 27305.0723 - val_r2_score: 0.4532 - learning_rate: 0.0250\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1724238848.0000 - mae: 26680.8945 - r2_score: 0.5544 - val_loss: 2035071232.0000 - val_mae: 26909.2988 - val_r2_score: 0.4510 - learning_rate: 0.0250\n",
      "Epoch 27/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1718105984.0000 - mae: 26609.4941 - r2_score: 0.5590 - val_loss: 2066267648.0000 - val_mae: 26843.5508 - val_r2_score: 0.4425 - learning_rate: 0.0250\n",
      "Epoch 28/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1672527872.0000 - mae: 26445.5527 - r2_score: 0.5558 - val_loss: 2014757248.0000 - val_mae: 27723.5703 - val_r2_score: 0.4564 - learning_rate: 0.0250\n",
      "Epoch 29/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1574526592.0000 - mae: 26356.3438 - r2_score: 0.5632 - val_loss: 2107233024.0000 - val_mae: 27076.3945 - val_r2_score: 0.4315 - learning_rate: 0.0250\n",
      "Epoch 30/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1617071104.0000 - mae: 26727.8926 - r2_score: 0.5452 - val_loss: 2085344768.0000 - val_mae: 27362.5020 - val_r2_score: 0.4374 - learning_rate: 0.0250\n",
      "Epoch 31/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1698358400.0000 - mae: 26500.3203 - r2_score: 0.5547 - val_loss: 2071317888.0000 - val_mae: 27240.1250 - val_r2_score: 0.4412 - learning_rate: 0.0250\n",
      "Epoch 32/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1572238464.0000 - mae: 26264.5195 - r2_score: 0.5678 - val_loss: 2075450112.0000 - val_mae: 26853.0391 - val_r2_score: 0.4401 - learning_rate: 0.0250\n",
      "Epoch 33/150\n",
      "\u001b[1m277/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1499323520.0000 - mae: 26201.1270 - r2_score: 0.5614\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1500768128.0000 - mae: 26205.0449 - r2_score: 0.5614 - val_loss: 2088719232.0000 - val_mae: 27148.0000 - val_r2_score: 0.4365 - learning_rate: 0.0250\n",
      "Epoch 34/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1667809920.0000 - mae: 26469.3867 - r2_score: 0.5824 - val_loss: 2000712576.0000 - val_mae: 26698.7832 - val_r2_score: 0.4602 - learning_rate: 0.0125\n",
      "Epoch 35/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1512396032.0000 - mae: 25654.2988 - r2_score: 0.5859 - val_loss: 2037580288.0000 - val_mae: 27126.8535 - val_r2_score: 0.4503 - learning_rate: 0.0125\n",
      "Epoch 36/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1583033344.0000 - mae: 26104.6973 - r2_score: 0.5860 - val_loss: 2076026496.0000 - val_mae: 26778.5684 - val_r2_score: 0.4399 - learning_rate: 0.0125\n",
      "Epoch 37/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1522413056.0000 - mae: 25718.8691 - r2_score: 0.6029 - val_loss: 2034788992.0000 - val_mae: 26891.5273 - val_r2_score: 0.4510 - learning_rate: 0.0125\n",
      "Epoch 38/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1553461888.0000 - mae: 26145.7520 - r2_score: 0.6001 - val_loss: 2069730176.0000 - val_mae: 26665.7578 - val_r2_score: 0.4416 - learning_rate: 0.0125\n",
      "Epoch 39/150\n",
      "\u001b[1m264/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1572302720.0000 - mae: 25595.8027 - r2_score: 0.5902\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1566637952.0000 - mae: 25592.0762 - r2_score: 0.5911 - val_loss: 2065451520.0000 - val_mae: 27022.4297 - val_r2_score: 0.4428 - learning_rate: 0.0125\n",
      "Epoch 40/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1336285824.0000 - mae: 24905.3555 - r2_score: 0.6362 - val_loss: 2050598912.0000 - val_mae: 26743.4707 - val_r2_score: 0.4468 - learning_rate: 0.0063\n",
      "Epoch 41/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1412616320.0000 - mae: 25167.3223 - r2_score: 0.6228 - val_loss: 2078597248.0000 - val_mae: 26711.7285 - val_r2_score: 0.4392 - learning_rate: 0.0063\n",
      "Epoch 42/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1426157952.0000 - mae: 25453.6973 - r2_score: 0.6213 - val_loss: 2077147776.0000 - val_mae: 26807.7109 - val_r2_score: 0.4396 - learning_rate: 0.0063\n",
      "Epoch 43/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1292755712.0000 - mae: 24610.9824 - r2_score: 0.6388 - val_loss: 2104477184.0000 - val_mae: 26875.9492 - val_r2_score: 0.4322 - learning_rate: 0.0063\n",
      "Epoch 44/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1397108352.0000 - mae: 25102.0762 - r2_score: 0.6419\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1397154688.0000 - mae: 25102.3984 - r2_score: 0.6418 - val_loss: 2036836096.0000 - val_mae: 26766.5820 - val_r2_score: 0.4505 - learning_rate: 0.0063\n",
      "Epoch 44: early stopping\n",
      "Restoring model weights from the end of the best epoch: 34.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 12633555968.0000 - mae: 94847.2422 - r2_score: -2.4012 - val_loss: 8743513088.0000 - val_mae: 80325.7891 - val_r2_score: -1.2421 - learning_rate: 0.0500\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8633311232.0000 - mae: 76644.5000 - r2_score: -1.2790 - val_loss: 5532965888.0000 - val_mae: 57887.5820 - val_r2_score: -0.4188 - learning_rate: 0.0500\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4492598272.0000 - mae: 48885.7383 - r2_score: -0.1068 - val_loss: 3465888512.0000 - val_mae: 39156.2812 - val_r2_score: 0.1112 - learning_rate: 0.0500\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2603794688.0000 - mae: 32920.7305 - r2_score: 0.2905 - val_loss: 2996664320.0000 - val_mae: 30195.9414 - val_r2_score: 0.2316 - learning_rate: 0.0500\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2293538304.0000 - mae: 29457.7559 - r2_score: 0.3954 - val_loss: 2999648256.0000 - val_mae: 29256.6895 - val_r2_score: 0.2308 - learning_rate: 0.0500\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2356814080.0000 - mae: 29353.3125 - r2_score: 0.3938 - val_loss: 3055023104.0000 - val_mae: 28820.0430 - val_r2_score: 0.2166 - learning_rate: 0.0500\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2220378880.0000 - mae: 29086.4375 - r2_score: 0.4091 - val_loss: 3592664576.0000 - val_mae: 29084.8164 - val_r2_score: 0.0787 - learning_rate: 0.0500\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2270425344.0000 - mae: 29024.7930 - r2_score: 0.4271 - val_loss: 3439352832.0000 - val_mae: 29025.4961 - val_r2_score: 0.1180 - learning_rate: 0.0500\n",
      "Epoch 9/150\n",
      "\u001b[1m268/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1972908160.0000 - mae: 28184.6387 - r2_score: 0.4397\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1982936576.0000 - mae: 28210.9023 - r2_score: 0.4390 - val_loss: 3772987136.0000 - val_mae: 30275.3418 - val_r2_score: 0.0325 - learning_rate: 0.0500\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1998346752.0000 - mae: 28219.8320 - r2_score: 0.4569 - val_loss: 3389264640.0000 - val_mae: 28776.2266 - val_r2_score: 0.1309 - learning_rate: 0.0250\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2282388480.0000 - mae: 28776.1797 - r2_score: 0.4448 - val_loss: 2879364608.0000 - val_mae: 28364.6836 - val_r2_score: 0.2616 - learning_rate: 0.0250\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2118073600.0000 - mae: 28046.0840 - r2_score: 0.4558 - val_loss: 2481937152.0000 - val_mae: 28254.4336 - val_r2_score: 0.3636 - learning_rate: 0.0250\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1887138304.0000 - mae: 27701.5527 - r2_score: 0.4754 - val_loss: 2710229504.0000 - val_mae: 28177.0586 - val_r2_score: 0.3050 - learning_rate: 0.0250\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2056043648.0000 - mae: 28175.4375 - r2_score: 0.4745 - val_loss: 2365233664.0000 - val_mae: 27938.0000 - val_r2_score: 0.3935 - learning_rate: 0.0250\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2075238400.0000 - mae: 27981.3047 - r2_score: 0.4796 - val_loss: 2231999232.0000 - val_mae: 27537.9004 - val_r2_score: 0.4276 - learning_rate: 0.0250\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1793485696.0000 - mae: 27355.6348 - r2_score: 0.5066 - val_loss: 2251025664.0000 - val_mae: 28046.7109 - val_r2_score: 0.4228 - learning_rate: 0.0250\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1874078336.0000 - mae: 27504.1992 - r2_score: 0.4948 - val_loss: 2288292096.0000 - val_mae: 27554.3281 - val_r2_score: 0.4132 - learning_rate: 0.0250\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1983220736.0000 - mae: 27917.5332 - r2_score: 0.4977 - val_loss: 2177118208.0000 - val_mae: 27412.2344 - val_r2_score: 0.4417 - learning_rate: 0.0250\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1818904960.0000 - mae: 27121.0469 - r2_score: 0.4871 - val_loss: 2239238400.0000 - val_mae: 27608.2637 - val_r2_score: 0.4258 - learning_rate: 0.0250\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1864320256.0000 - mae: 27474.6973 - r2_score: 0.5232 - val_loss: 2200391936.0000 - val_mae: 27600.6738 - val_r2_score: 0.4358 - learning_rate: 0.0250\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2016525440.0000 - mae: 27661.5547 - r2_score: 0.5092 - val_loss: 2215740416.0000 - val_mae: 27216.7598 - val_r2_score: 0.4318 - learning_rate: 0.0250\n",
      "Epoch 22/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1871237760.0000 - mae: 27309.9453 - r2_score: 0.5167 - val_loss: 2231707648.0000 - val_mae: 27448.5469 - val_r2_score: 0.4277 - learning_rate: 0.0250\n",
      "Epoch 23/150\n",
      "\u001b[1m276/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1759475328.0000 - mae: 26996.0918 - r2_score: 0.5281\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1760982272.0000 - mae: 26999.9375 - r2_score: 0.5278 - val_loss: 2320650752.0000 - val_mae: 27733.3535 - val_r2_score: 0.4049 - learning_rate: 0.0250\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1882456704.0000 - mae: 26733.8906 - r2_score: 0.5320 - val_loss: 2223194624.0000 - val_mae: 27424.9395 - val_r2_score: 0.4299 - learning_rate: 0.0125\n",
      "Epoch 25/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1680968576.0000 - mae: 26263.4141 - r2_score: 0.5360 - val_loss: 2196899584.0000 - val_mae: 27244.2637 - val_r2_score: 0.4366 - learning_rate: 0.0125\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1644189568.0000 - mae: 26339.7227 - r2_score: 0.5587 - val_loss: 2200427264.0000 - val_mae: 27724.3809 - val_r2_score: 0.4357 - learning_rate: 0.0125\n",
      "Epoch 27/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1646252032.0000 - mae: 26271.2949 - r2_score: 0.5568 - val_loss: 2195171072.0000 - val_mae: 27410.7734 - val_r2_score: 0.4371 - learning_rate: 0.0125\n",
      "Epoch 28/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1659799552.0000 - mae: 26288.8086 - r2_score: 0.5666\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1659853568.0000 - mae: 26288.6016 - r2_score: 0.5666 - val_loss: 2216163840.0000 - val_mae: 27779.2109 - val_r2_score: 0.4317 - learning_rate: 0.0125\n",
      "Epoch 28: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 12574404608.0000 - mae: 95187.9922 - r2_score: -2.4967 - val_loss: 8170160128.0000 - val_mae: 77172.3125 - val_r2_score: -1.1044 - learning_rate: 0.0500\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8553602048.0000 - mae: 76304.4453 - r2_score: -1.2592 - val_loss: 5352978944.0000 - val_mae: 57889.7344 - val_r2_score: -0.3787 - learning_rate: 0.0500\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4237236736.0000 - mae: 48138.8359 - r2_score: -0.1510 - val_loss: 3788358400.0000 - val_mae: 42015.1016 - val_r2_score: 0.0242 - learning_rate: 0.0500\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2792016640.0000 - mae: 33232.4531 - r2_score: 0.2812 - val_loss: 3102865664.0000 - val_mae: 30665.3945 - val_r2_score: 0.2008 - learning_rate: 0.0500\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2326438144.0000 - mae: 29425.5547 - r2_score: 0.3811 - val_loss: 3250041600.0000 - val_mae: 29251.1973 - val_r2_score: 0.1629 - learning_rate: 0.0500\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2256379392.0000 - mae: 29155.5156 - r2_score: 0.3994 - val_loss: 2843350528.0000 - val_mae: 28171.6387 - val_r2_score: 0.2677 - learning_rate: 0.0500\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2106937344.0000 - mae: 28794.5332 - r2_score: 0.4269 - val_loss: 2850180096.0000 - val_mae: 28270.7461 - val_r2_score: 0.2659 - learning_rate: 0.0500\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2318441984.0000 - mae: 29027.8145 - r2_score: 0.4091 - val_loss: 2804368128.0000 - val_mae: 28133.9512 - val_r2_score: 0.2777 - learning_rate: 0.0500\n",
      "Epoch 9/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2206940416.0000 - mae: 28948.6406 - r2_score: 0.4151 - val_loss: 2813894400.0000 - val_mae: 28194.8496 - val_r2_score: 0.2752 - learning_rate: 0.0500\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2289678848.0000 - mae: 29253.9375 - r2_score: 0.4183 - val_loss: 2464759040.0000 - val_mae: 28124.3594 - val_r2_score: 0.3652 - learning_rate: 0.0500\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2180927744.0000 - mae: 28655.4551 - r2_score: 0.4379 - val_loss: 2263309056.0000 - val_mae: 27539.4102 - val_r2_score: 0.4170 - learning_rate: 0.0500\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2036228608.0000 - mae: 28491.7754 - r2_score: 0.4477 - val_loss: 2301346560.0000 - val_mae: 28166.0547 - val_r2_score: 0.4073 - learning_rate: 0.0500\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2125287168.0000 - mae: 28827.3730 - r2_score: 0.4439 - val_loss: 2243814912.0000 - val_mae: 27727.1582 - val_r2_score: 0.4221 - learning_rate: 0.0500\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2003057280.0000 - mae: 28033.4258 - r2_score: 0.4692 - val_loss: 2223095808.0000 - val_mae: 29136.3555 - val_r2_score: 0.4274 - learning_rate: 0.0500\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2115085824.0000 - mae: 28687.1992 - r2_score: 0.4553 - val_loss: 2415787776.0000 - val_mae: 28203.2812 - val_r2_score: 0.3778 - learning_rate: 0.0500\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1958344832.0000 - mae: 27788.8203 - r2_score: 0.4633 - val_loss: 2228674304.0000 - val_mae: 28235.6504 - val_r2_score: 0.4260 - learning_rate: 0.0500\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1966966656.0000 - mae: 27972.4277 - r2_score: 0.4728 - val_loss: 2185672448.0000 - val_mae: 28268.2949 - val_r2_score: 0.4370 - learning_rate: 0.0500\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2007175808.0000 - mae: 28108.4883 - r2_score: 0.4789 - val_loss: 2248969472.0000 - val_mae: 27620.7266 - val_r2_score: 0.4207 - learning_rate: 0.0500\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1905564544.0000 - mae: 27748.1777 - r2_score: 0.4921 - val_loss: 2211248640.0000 - val_mae: 27864.2871 - val_r2_score: 0.4305 - learning_rate: 0.0500\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2020321536.0000 - mae: 28235.8613 - r2_score: 0.4681 - val_loss: 2170398464.0000 - val_mae: 27982.3340 - val_r2_score: 0.4410 - learning_rate: 0.0500\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1852061568.0000 - mae: 27656.0527 - r2_score: 0.4898 - val_loss: 2209469696.0000 - val_mae: 28344.2109 - val_r2_score: 0.4309 - learning_rate: 0.0500\n",
      "Epoch 22/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1985968768.0000 - mae: 27584.8672 - r2_score: 0.4839 - val_loss: 2265277184.0000 - val_mae: 27734.3691 - val_r2_score: 0.4165 - learning_rate: 0.0500\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1969739904.0000 - mae: 28043.7500 - r2_score: 0.4789 - val_loss: 2313314816.0000 - val_mae: 29317.7422 - val_r2_score: 0.4042 - learning_rate: 0.0500\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1958776448.0000 - mae: 28093.7305 - r2_score: 0.5011 - val_loss: 2226777856.0000 - val_mae: 27624.6934 - val_r2_score: 0.4265 - learning_rate: 0.0500\n",
      "Epoch 25/150\n",
      "\u001b[1m273/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1850256384.0000 - mae: 27757.3281 - r2_score: 0.5065\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1852243584.0000 - mae: 27764.7695 - r2_score: 0.5062 - val_loss: 2206931456.0000 - val_mae: 28237.6621 - val_r2_score: 0.4316 - learning_rate: 0.0500\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1878057856.0000 - mae: 27312.1250 - r2_score: 0.5100 - val_loss: 2216536320.0000 - val_mae: 28309.1523 - val_r2_score: 0.4291 - learning_rate: 0.0250\n",
      "Epoch 27/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1801535360.0000 - mae: 26968.2969 - r2_score: 0.5296 - val_loss: 2170781440.0000 - val_mae: 27830.4668 - val_r2_score: 0.4409 - learning_rate: 0.0250\n",
      "Epoch 28/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1729040000.0000 - mae: 27119.4512 - r2_score: 0.5369 - val_loss: 2205990144.0000 - val_mae: 27860.7500 - val_r2_score: 0.4318 - learning_rate: 0.0250\n",
      "Epoch 29/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1697471104.0000 - mae: 26748.7090 - r2_score: 0.5573 - val_loss: 2175848704.0000 - val_mae: 28055.8516 - val_r2_score: 0.4396 - learning_rate: 0.0250\n",
      "Epoch 30/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1839276032.0000 - mae: 27303.2480 - r2_score: 0.5492\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1838872064.0000 - mae: 27302.6602 - r2_score: 0.5492 - val_loss: 2280341504.0000 - val_mae: 28024.1562 - val_r2_score: 0.4127 - learning_rate: 0.0250\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 12818117632.0000 - mae: 94861.2578 - r2_score: -2.2449 - val_loss: 7481311744.0000 - val_mae: 73437.9609 - val_r2_score: -0.9920 - learning_rate: 0.0500\n",
      "Epoch 2/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7065633792.0000 - mae: 67325.3047 - r2_score: -0.8476 - val_loss: 4274910976.0000 - val_mae: 49207.0508 - val_r2_score: -0.1382 - learning_rate: 0.0500\n",
      "Epoch 3/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3280826368.0000 - mae: 38493.3281 - r2_score: 0.1471 - val_loss: 2630564608.0000 - val_mae: 30322.0918 - val_r2_score: 0.2996 - learning_rate: 0.0500\n",
      "Epoch 4/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2338263552.0000 - mae: 30057.6895 - r2_score: 0.3758 - val_loss: 2548924928.0000 - val_mae: 28503.0078 - val_r2_score: 0.3213 - learning_rate: 0.0500\n",
      "Epoch 5/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2366437888.0000 - mae: 29705.8145 - r2_score: 0.3840 - val_loss: 2671759616.0000 - val_mae: 28067.4570 - val_r2_score: 0.2886 - learning_rate: 0.0500\n",
      "Epoch 6/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2305066240.0000 - mae: 29230.6055 - r2_score: 0.4081 - val_loss: 2573285888.0000 - val_mae: 28134.1328 - val_r2_score: 0.3148 - learning_rate: 0.0500\n",
      "Epoch 7/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2195769600.0000 - mae: 29152.9023 - r2_score: 0.4025 - val_loss: 2732198656.0000 - val_mae: 27852.0469 - val_r2_score: 0.2725 - learning_rate: 0.0500\n",
      "Epoch 8/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2190040320.0000 - mae: 29093.4785 - r2_score: 0.4116 - val_loss: 2556881408.0000 - val_mae: 28015.2578 - val_r2_score: 0.3192 - learning_rate: 0.0500\n",
      "Epoch 9/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2107982592.0000 - mae: 28749.9707 - r2_score: 0.4249 - val_loss: 2539286784.0000 - val_mae: 27987.1250 - val_r2_score: 0.3239 - learning_rate: 0.0500\n",
      "Epoch 10/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2119801216.0000 - mae: 28735.5234 - r2_score: 0.4377 - val_loss: 2277523456.0000 - val_mae: 27433.2676 - val_r2_score: 0.3936 - learning_rate: 0.0500\n",
      "Epoch 11/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2091534976.0000 - mae: 28481.2637 - r2_score: 0.4310 - val_loss: 2183068416.0000 - val_mae: 27509.5488 - val_r2_score: 0.4187 - learning_rate: 0.0500\n",
      "Epoch 12/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2117549568.0000 - mae: 28730.8125 - r2_score: 0.4343 - val_loss: 2130904960.0000 - val_mae: 27711.7305 - val_r2_score: 0.4326 - learning_rate: 0.0500\n",
      "Epoch 13/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2128142336.0000 - mae: 28834.5176 - r2_score: 0.4414 - val_loss: 2107823872.0000 - val_mae: 27269.7090 - val_r2_score: 0.4388 - learning_rate: 0.0500\n",
      "Epoch 14/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2179372032.0000 - mae: 28816.7969 - r2_score: 0.4379 - val_loss: 2204174080.0000 - val_mae: 27499.4121 - val_r2_score: 0.4131 - learning_rate: 0.0500\n",
      "Epoch 15/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2252036608.0000 - mae: 28920.6660 - r2_score: 0.4364 - val_loss: 2106641408.0000 - val_mae: 27066.3477 - val_r2_score: 0.4391 - learning_rate: 0.0500\n",
      "Epoch 16/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2020727296.0000 - mae: 28278.6973 - r2_score: 0.4609 - val_loss: 2235438336.0000 - val_mae: 27605.0469 - val_r2_score: 0.4048 - learning_rate: 0.0500\n",
      "Epoch 17/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2041070208.0000 - mae: 28295.9277 - r2_score: 0.4626 - val_loss: 2102353280.0000 - val_mae: 27561.0723 - val_r2_score: 0.4402 - learning_rate: 0.0500\n",
      "Epoch 18/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2155130368.0000 - mae: 28443.4922 - r2_score: 0.4587 - val_loss: 2095888000.0000 - val_mae: 27419.9785 - val_r2_score: 0.4419 - learning_rate: 0.0500\n",
      "Epoch 19/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2051260288.0000 - mae: 28217.5859 - r2_score: 0.4647 - val_loss: 2107477632.0000 - val_mae: 27243.1289 - val_r2_score: 0.4389 - learning_rate: 0.0500\n",
      "Epoch 20/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2065459072.0000 - mae: 28329.0000 - r2_score: 0.4649 - val_loss: 2085199488.0000 - val_mae: 27804.5117 - val_r2_score: 0.4448 - learning_rate: 0.0500\n",
      "Epoch 21/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2082313344.0000 - mae: 28422.7852 - r2_score: 0.4666 - val_loss: 2106258048.0000 - val_mae: 28642.8633 - val_r2_score: 0.4392 - learning_rate: 0.0500\n",
      "Epoch 22/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1838450304.0000 - mae: 27719.1797 - r2_score: 0.4796 - val_loss: 2136965888.0000 - val_mae: 27967.7012 - val_r2_score: 0.4310 - learning_rate: 0.0500\n",
      "Epoch 23/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1921536768.0000 - mae: 27747.1719 - r2_score: 0.4684 - val_loss: 2141475200.0000 - val_mae: 27814.4180 - val_r2_score: 0.4298 - learning_rate: 0.0500\n",
      "Epoch 24/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2021462400.0000 - mae: 28672.2109 - r2_score: 0.4686 - val_loss: 2109670784.0000 - val_mae: 27133.9023 - val_r2_score: 0.4383 - learning_rate: 0.0500\n",
      "Epoch 25/150\n",
      "\u001b[1m342/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2056583040.0000 - mae: 28397.0918 - r2_score: 0.4768\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2055797760.0000 - mae: 28394.3594 - r2_score: 0.4766 - val_loss: 2112045312.0000 - val_mae: 27288.9941 - val_r2_score: 0.4376 - learning_rate: 0.0500\n",
      "Epoch 26/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1940365952.0000 - mae: 27603.0234 - r2_score: 0.4999 - val_loss: 2081894784.0000 - val_mae: 27436.8320 - val_r2_score: 0.4457 - learning_rate: 0.0250\n",
      "Epoch 27/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1787109248.0000 - mae: 27306.9902 - r2_score: 0.5119 - val_loss: 2058167424.0000 - val_mae: 27218.2500 - val_r2_score: 0.4520 - learning_rate: 0.0250\n",
      "Epoch 28/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1890880128.0000 - mae: 27529.4102 - r2_score: 0.5114 - val_loss: 2133088000.0000 - val_mae: 26866.4902 - val_r2_score: 0.4320 - learning_rate: 0.0250\n",
      "Epoch 29/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1960763776.0000 - mae: 27596.5684 - r2_score: 0.5119 - val_loss: 2034885504.0000 - val_mae: 27290.3164 - val_r2_score: 0.4582 - learning_rate: 0.0250\n",
      "Epoch 30/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1770754688.0000 - mae: 27023.8926 - r2_score: 0.5272 - val_loss: 2104131584.0000 - val_mae: 27483.6680 - val_r2_score: 0.4398 - learning_rate: 0.0250\n",
      "Epoch 31/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1813950464.0000 - mae: 27283.4668 - r2_score: 0.5236 - val_loss: 2095577344.0000 - val_mae: 27670.6641 - val_r2_score: 0.4420 - learning_rate: 0.0250\n",
      "Epoch 32/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1843593856.0000 - mae: 27438.9844 - r2_score: 0.5215 - val_loss: 2150544640.0000 - val_mae: 27439.7324 - val_r2_score: 0.4274 - learning_rate: 0.0250\n",
      "Epoch 33/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1699274112.0000 - mae: 27005.3809 - r2_score: 0.5323 - val_loss: 2106073856.0000 - val_mae: 27106.8496 - val_r2_score: 0.4392 - learning_rate: 0.0250\n",
      "Epoch 34/150\n",
      "\u001b[1m344/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1699371904.0000 - mae: 26947.9121 - r2_score: 0.5352\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1701205888.0000 - mae: 26952.6855 - r2_score: 0.5350 - val_loss: 2166782720.0000 - val_mae: 27599.9160 - val_r2_score: 0.4231 - learning_rate: 0.0250\n",
      "Epoch 35/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1686507776.0000 - mae: 26768.8926 - r2_score: 0.5392 - val_loss: 2141474048.0000 - val_mae: 27146.2734 - val_r2_score: 0.4298 - learning_rate: 0.0125\n",
      "Epoch 36/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1735939200.0000 - mae: 26738.3750 - r2_score: 0.5592 - val_loss: 2069941248.0000 - val_mae: 26796.5508 - val_r2_score: 0.4489 - learning_rate: 0.0125\n",
      "Epoch 37/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1623273088.0000 - mae: 26538.6191 - r2_score: 0.5595 - val_loss: 2090579968.0000 - val_mae: 27800.7676 - val_r2_score: 0.4434 - learning_rate: 0.0125\n",
      "Epoch 38/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1621364608.0000 - mae: 26617.9727 - r2_score: 0.5685 - val_loss: 2070900352.0000 - val_mae: 27295.5469 - val_r2_score: 0.4486 - learning_rate: 0.0125\n",
      "Epoch 39/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1579424896.0000 - mae: 26389.2656 - r2_score: 0.5759\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1579619712.0000 - mae: 26389.9766 - r2_score: 0.5759 - val_loss: 2152799488.0000 - val_mae: 27421.5098 - val_r2_score: 0.4268 - learning_rate: 0.0125\n",
      "Epoch 39: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    clone(preprocessor), \n",
    "    GridSearchCV(\n",
    "        estimator=KerasRegressor(\n",
    "            model=build_model,\n",
    "            epochs=150,\n",
    "            batch_size=64,\n",
    "            verbose=1,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[\n",
    "                EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "                ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-6, verbose=1)\n",
    "            ]\n",
    "        ),\n",
    "        param_grid={\n",
    "            'model__learning_rate': [5e-2]\n",
    "        },\n",
    "        scoring=\"r2\",\n",
    "        cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        verbose=1,\n",
    "    )\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ff61d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__learning_rate': 0.05}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = model[-1]\n",
    "best_params = search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea244a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m436/436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step\n",
      "Train R2: 0.5996\n",
      "Train RMSE: 38926.7294\n",
      "Train MAE: 24265.8338\n"
     ]
    }
   ],
   "source": [
    "result_train = salary.evaluate_train_predictions(model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6182d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n",
      "Test R2: 0.4907\n",
      "Test RMSE: 41605.9919\n",
      "Test MAE: 26693.9291\n"
     ]
    }
   ],
   "source": [
    "result_test = salary.evaluate_test_predictions(model.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
