{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc2fc48f-dbcc-4e6c-bc0e-8d1e72e670a4",
   "metadata": {},
   "source": [
    "# Salary Prediction from LinkedIn Job Postings - Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3375fb27-0be7-4da8-9378-9137587226e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vm/77wrgjgj5wzbyghx353b7gym0000gn/T/ipykernel_3272/3165727885.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd, numpy as np\n",
      "/Users/nginyc/repos/job_posting_salary_prediction/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import salary\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from category_encoders import TargetEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import tensorflow.keras as keras\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "337486df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcc83ff-8948-46b2-94bd-096093c31122",
   "metadata": {},
   "source": [
    "## Train & Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adfcb495",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train) = salary.get_train_dataset()\n",
    "(X_test, y_test) = salary.get_test_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ea4d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('one_hot_encoder', OneHotEncoder(use_cat_names=True), ['norm_title', 'clustered_edu_req', 'clustered_pref_qual', 'clustered_req_skill', 'location_state', 'company_industries', 'formatted_experience_level', 'formatted_work_type']),\n",
    "            ('target_encoder', TargetEncoder(), ['norm_title', 'clustered_edu_req', 'clustered_pref_qual', 'clustered_req_skill', 'location_state', 'company_industries', 'formatted_experience_level', 'formatted_work_type']),\n",
    "            ('experience_level', salary.experience_level_encoder, ['formatted_experience_level']),\n",
    "            ('work_type', salary.work_type_encoder, ['formatted_work_type']),\n",
    "            ('remote_allowed', 'passthrough', ['remote_allowed']),\n",
    "            ('company_employee_count', SimpleImputer(strategy='median'), ['company_employee_count']),\n",
    "        ],\n",
    "        remainder='drop'\n",
    "    ),\n",
    "    StandardScaler(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ec93e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    n_units_1=256,\n",
    "    n_units_2=192,\n",
    "    n_units_3=64,\n",
    "    n_units_4=32,\n",
    "    dropout_rate=0.3,\n",
    "    learning_rate=0.05,\n",
    "    optimizer_name=\"adamw\"\n",
    "):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(318,)))\n",
    "\n",
    "    # Layer 1\n",
    "    model.add(keras.layers.Dense(n_units_1, activation='leaky_relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(keras.layers.Dense(n_units_2, activation='leaky_relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    # Layer 3\n",
    "    if n_units_3:\n",
    "        model.add(keras.layers.Dense(n_units_3, activation='leaky_relu'))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    # Layer 4\n",
    "    if n_units_4:\n",
    "        model.add(keras.layers.Dense(n_units_4, activation='leaky_relu'))\n",
    "        model.add(keras.layers.BatchNormalization())\n",
    "        model.add(keras.layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(keras.layers.Dense(1))  # Output layer for regression\n",
    "\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == \"adamw\":\n",
    "        optimizer = keras.optimizers.AdamW(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae', 'r2_score'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9844899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 13094193152.0000 - mae: 96726.5234 - r2_score: -2.5084 - val_loss: 13175993344.0000 - val_mae: 97297.7109 - val_r2_score: -2.4540 - learning_rate: 0.0100\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12959981568.0000 - mae: 95593.9922 - r2_score: -2.3289 - val_loss: 12633285632.0000 - val_mae: 95318.1719 - val_r2_score: -2.3118 - learning_rate: 0.0100\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12543975424.0000 - mae: 94111.0781 - r2_score: -2.1979 - val_loss: 11938516992.0000 - val_mae: 92966.8516 - val_r2_score: -2.1296 - learning_rate: 0.0100\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11326956544.0000 - mae: 90177.5078 - r2_score: -2.1159 - val_loss: 10928696320.0000 - val_mae: 88794.5859 - val_r2_score: -1.8649 - learning_rate: 0.0100\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10673055744.0000 - mae: 87143.4688 - r2_score: -1.8535 - val_loss: 10211832832.0000 - val_mae: 85250.9297 - val_r2_score: -1.6770 - learning_rate: 0.0100\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9582441472.0000 - mae: 82213.5078 - r2_score: -1.5470 - val_loss: 8838802432.0000 - val_mae: 78706.5469 - val_r2_score: -1.3171 - learning_rate: 0.0100\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8713444352.0000 - mae: 77811.7422 - r2_score: -1.2725 - val_loss: 8273327616.0000 - val_mae: 74812.2969 - val_r2_score: -1.1688 - learning_rate: 0.0100\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7720287744.0000 - mae: 72720.5547 - r2_score: -1.0290 - val_loss: 7616799744.0000 - val_mae: 69798.0391 - val_r2_score: -0.9967 - learning_rate: 0.0100\n",
      "Epoch 9/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6998747648.0000 - mae: 67773.1328 - r2_score: -0.7694 - val_loss: 7107008512.0000 - val_mae: 67156.3047 - val_r2_score: -0.8631 - learning_rate: 0.0100\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5992224256.0000 - mae: 62019.0781 - r2_score: -0.5486 - val_loss: 6508951552.0000 - val_mae: 59995.6367 - val_r2_score: -0.7063 - learning_rate: 0.0100\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5176867328.0000 - mae: 57157.4258 - r2_score: -0.3622 - val_loss: 6315118080.0000 - val_mae: 54994.4922 - val_r2_score: -0.6555 - learning_rate: 0.0100\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4750602240.0000 - mae: 52979.2188 - r2_score: -0.1886 - val_loss: 4901935104.0000 - val_mae: 51285.1602 - val_r2_score: -0.2850 - learning_rate: 0.0100\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3934134272.0000 - mae: 47719.5977 - r2_score: -0.0504 - val_loss: 4322115584.0000 - val_mae: 48285.5664 - val_r2_score: -0.1330 - learning_rate: 0.0100\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3612536832.0000 - mae: 44353.2070 - r2_score: 0.0748 - val_loss: 3624310016.0000 - val_mae: 42831.8477 - val_r2_score: 0.0499 - learning_rate: 0.0100\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3162759680.0000 - mae: 40113.6758 - r2_score: 0.1795 - val_loss: 3475641600.0000 - val_mae: 41049.4219 - val_r2_score: 0.0889 - learning_rate: 0.0100\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2833070336.0000 - mae: 37208.2969 - r2_score: 0.2477 - val_loss: 2974122496.0000 - val_mae: 36288.6133 - val_r2_score: 0.2203 - learning_rate: 0.0100\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2648013312.0000 - mae: 34507.5977 - r2_score: 0.3285 - val_loss: 2853457152.0000 - val_mae: 35453.2812 - val_r2_score: 0.2520 - learning_rate: 0.0100\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2564366592.0000 - mae: 32542.2441 - r2_score: 0.3824 - val_loss: 2627902464.0000 - val_mae: 32513.4961 - val_r2_score: 0.3111 - learning_rate: 0.0100\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2109707136.0000 - mae: 30500.6543 - r2_score: 0.4331 - val_loss: 2539143936.0000 - val_mae: 29950.2266 - val_r2_score: 0.3344 - learning_rate: 0.0100\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1929881344.0000 - mae: 29130.5703 - r2_score: 0.4658 - val_loss: 2357696768.0000 - val_mae: 29098.2402 - val_r2_score: 0.3819 - learning_rate: 0.0100\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2008855808.0000 - mae: 28644.5449 - r2_score: 0.4928 - val_loss: 2372379904.0000 - val_mae: 28840.9531 - val_r2_score: 0.3781 - learning_rate: 0.0100\n",
      "Epoch 22/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1832042368.0000 - mae: 27443.7734 - r2_score: 0.5074 - val_loss: 2251817472.0000 - val_mae: 27609.1914 - val_r2_score: 0.4097 - learning_rate: 0.0100\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1857723264.0000 - mae: 27278.3965 - r2_score: 0.5155 - val_loss: 2341849344.0000 - val_mae: 28629.8984 - val_r2_score: 0.3861 - learning_rate: 0.0100\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2054594304.0000 - mae: 27607.5078 - r2_score: 0.5146 - val_loss: 2253500160.0000 - val_mae: 27734.3047 - val_r2_score: 0.4093 - learning_rate: 0.0100\n",
      "Epoch 25/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1688037760.0000 - mae: 26715.8828 - r2_score: 0.5478 - val_loss: 2223131648.0000 - val_mae: 27601.4277 - val_r2_score: 0.4172 - learning_rate: 0.0100\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1896636416.0000 - mae: 27343.6504 - r2_score: 0.5397 - val_loss: 2208952832.0000 - val_mae: 27319.7676 - val_r2_score: 0.4209 - learning_rate: 0.0100\n",
      "Epoch 27/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1942505728.0000 - mae: 27386.3398 - r2_score: 0.5437 - val_loss: 2237237248.0000 - val_mae: 28036.6777 - val_r2_score: 0.4135 - learning_rate: 0.0100\n",
      "Epoch 28/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1731493504.0000 - mae: 27042.8594 - r2_score: 0.5536 - val_loss: 2221679104.0000 - val_mae: 27705.6055 - val_r2_score: 0.4176 - learning_rate: 0.0100\n",
      "Epoch 29/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1660318976.0000 - mae: 26275.0449 - r2_score: 0.5499 - val_loss: 2333726464.0000 - val_mae: 27860.2734 - val_r2_score: 0.3882 - learning_rate: 0.0100\n",
      "Epoch 30/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1777064448.0000 - mae: 27136.5859 - r2_score: 0.5619 - val_loss: 2241295104.0000 - val_mae: 27602.0625 - val_r2_score: 0.4125 - learning_rate: 0.0100\n",
      "Epoch 31/150\n",
      "\u001b[1m277/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1702116224.0000 - mae: 26893.1719 - r2_score: 0.5558\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1702382336.0000 - mae: 26892.5020 - r2_score: 0.5558 - val_loss: 2279398656.0000 - val_mae: 27633.1660 - val_r2_score: 0.4025 - learning_rate: 0.0100\n",
      "Epoch 32/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1545840768.0000 - mae: 26091.4766 - r2_score: 0.5892 - val_loss: 2249422080.0000 - val_mae: 27658.1953 - val_r2_score: 0.4103 - learning_rate: 0.0050\n",
      "Epoch 33/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1606454528.0000 - mae: 26365.9805 - r2_score: 0.5740 - val_loss: 2200972544.0000 - val_mae: 27548.8457 - val_r2_score: 0.4230 - learning_rate: 0.0050\n",
      "Epoch 34/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1590352128.0000 - mae: 25664.3770 - r2_score: 0.5953 - val_loss: 2196342784.0000 - val_mae: 27207.6289 - val_r2_score: 0.4242 - learning_rate: 0.0050\n",
      "Epoch 35/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1572465408.0000 - mae: 26020.6113 - r2_score: 0.5945 - val_loss: 2234569984.0000 - val_mae: 27343.7676 - val_r2_score: 0.4142 - learning_rate: 0.0050\n",
      "Epoch 36/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1617345280.0000 - mae: 25948.6270 - r2_score: 0.6007 - val_loss: 2237597440.0000 - val_mae: 27185.2480 - val_r2_score: 0.4134 - learning_rate: 0.0050\n",
      "Epoch 37/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1606335616.0000 - mae: 25752.7539 - r2_score: 0.5938 - val_loss: 2214973696.0000 - val_mae: 27489.3027 - val_r2_score: 0.4194 - learning_rate: 0.0050\n",
      "Epoch 38/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1563473792.0000 - mae: 26174.6738 - r2_score: 0.5946 - val_loss: 2176425984.0000 - val_mae: 27486.4668 - val_r2_score: 0.4295 - learning_rate: 0.0050\n",
      "Epoch 39/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1539705600.0000 - mae: 25750.9160 - r2_score: 0.6079 - val_loss: 2196498944.0000 - val_mae: 27427.2148 - val_r2_score: 0.4242 - learning_rate: 0.0050\n",
      "Epoch 40/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1515244928.0000 - mae: 26017.4375 - r2_score: 0.6066 - val_loss: 2184775424.0000 - val_mae: 27554.1641 - val_r2_score: 0.4273 - learning_rate: 0.0050\n",
      "Epoch 41/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1554420480.0000 - mae: 25900.2969 - r2_score: 0.6002 - val_loss: 2218887424.0000 - val_mae: 27786.6953 - val_r2_score: 0.4183 - learning_rate: 0.0050\n",
      "Epoch 42/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1594719872.0000 - mae: 25900.9609 - r2_score: 0.5958 - val_loss: 2237316864.0000 - val_mae: 27720.6348 - val_r2_score: 0.4135 - learning_rate: 0.0050\n",
      "Epoch 43/150\n",
      "\u001b[1m277/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1569386496.0000 - mae: 26007.6562 - r2_score: 0.5983\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1569015808.0000 - mae: 26007.2793 - r2_score: 0.5984 - val_loss: 2206175232.0000 - val_mae: 27679.6152 - val_r2_score: 0.4217 - learning_rate: 0.0050\n",
      "Epoch 44/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1548817280.0000 - mae: 25571.8730 - r2_score: 0.6052 - val_loss: 2208600576.0000 - val_mae: 27379.5117 - val_r2_score: 0.4210 - learning_rate: 0.0025\n",
      "Epoch 45/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1418407680.0000 - mae: 25078.8379 - r2_score: 0.6179 - val_loss: 2200495360.0000 - val_mae: 27463.8789 - val_r2_score: 0.4231 - learning_rate: 0.0025\n",
      "Epoch 46/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1525255424.0000 - mae: 25832.5039 - r2_score: 0.6130 - val_loss: 2185813504.0000 - val_mae: 27358.8047 - val_r2_score: 0.4270 - learning_rate: 0.0025\n",
      "Epoch 47/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1448665472.0000 - mae: 25424.2637 - r2_score: 0.6212 - val_loss: 2237730816.0000 - val_mae: 27320.8809 - val_r2_score: 0.4134 - learning_rate: 0.0025\n",
      "Epoch 48/150\n",
      "\u001b[1m268/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1451459072.0000 - mae: 24888.1973 - r2_score: 0.6149\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1452911744.0000 - mae: 24902.8477 - r2_score: 0.6150 - val_loss: 2248730368.0000 - val_mae: 27740.0098 - val_r2_score: 0.4105 - learning_rate: 0.0025\n",
      "Epoch 48: early stopping\n",
      "Restoring model weights from the end of the best epoch: 38.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 13224439808.0000 - mae: 96510.0859 - r2_score: -2.3911 - val_loss: 12747614208.0000 - val_mae: 96731.6641 - val_r2_score: -2.6147 - learning_rate: 0.0100\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12590411776.0000 - mae: 94737.6953 - r2_score: -2.4134 - val_loss: 12267649024.0000 - val_mae: 95022.1094 - val_r2_score: -2.4786 - learning_rate: 0.0100\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12733045760.0000 - mae: 94568.0547 - r2_score: -2.1719 - val_loss: 11501631488.0000 - val_mae: 91811.2344 - val_r2_score: -2.2614 - learning_rate: 0.0100\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11490034688.0000 - mae: 90622.6016 - r2_score: -2.0893 - val_loss: 10663946240.0000 - val_mae: 88493.2188 - val_r2_score: -2.0239 - learning_rate: 0.0100\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10401214464.0000 - mae: 86273.7500 - r2_score: -1.8667 - val_loss: 10043026432.0000 - val_mae: 85336.3750 - val_r2_score: -1.8478 - learning_rate: 0.0100\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9484860416.0000 - mae: 81428.7109 - r2_score: -1.5325 - val_loss: 8665294848.0000 - val_mae: 78633.3281 - val_r2_score: -1.4571 - learning_rate: 0.0100\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8526619136.0000 - mae: 76694.2969 - r2_score: -1.2486 - val_loss: 7952076800.0000 - val_mae: 73923.1094 - val_r2_score: -1.2549 - learning_rate: 0.0100\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7575498752.0000 - mae: 72075.0547 - r2_score: -1.0377 - val_loss: 7414019584.0000 - val_mae: 70253.1562 - val_r2_score: -1.1023 - learning_rate: 0.0100\n",
      "Epoch 9/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6698525184.0000 - mae: 67352.4141 - r2_score: -0.7908 - val_loss: 6496876032.0000 - val_mae: 64293.4492 - val_r2_score: -0.8423 - learning_rate: 0.0100\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5647666176.0000 - mae: 61305.8281 - r2_score: -0.5740 - val_loss: 5742348800.0000 - val_mae: 59871.0781 - val_r2_score: -0.6283 - learning_rate: 0.0100\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5036247552.0000 - mae: 56584.8984 - r2_score: -0.3720 - val_loss: 4924664832.0000 - val_mae: 55164.1875 - val_r2_score: -0.3964 - learning_rate: 0.0100\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4421924864.0000 - mae: 51894.3438 - r2_score: -0.1842 - val_loss: 3898301952.0000 - val_mae: 47409.5352 - val_r2_score: -0.1054 - learning_rate: 0.0100\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4056521728.0000 - mae: 48137.6094 - r2_score: -0.0476 - val_loss: 3707683072.0000 - val_mae: 45743.5430 - val_r2_score: -0.0514 - learning_rate: 0.0100\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3219447808.0000 - mae: 42463.0352 - r2_score: 0.0785 - val_loss: 3571889408.0000 - val_mae: 43583.7070 - val_r2_score: -0.0128 - learning_rate: 0.0100\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3019664896.0000 - mae: 40339.6328 - r2_score: 0.1842 - val_loss: 3090277120.0000 - val_mae: 39613.9883 - val_r2_score: 0.1237 - learning_rate: 0.0100\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2704176384.0000 - mae: 36561.8516 - r2_score: 0.2638 - val_loss: 2936643840.0000 - val_mae: 37018.6016 - val_r2_score: 0.1673 - learning_rate: 0.0100\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2433403904.0000 - mae: 33704.0469 - r2_score: 0.3433 - val_loss: 2467838976.0000 - val_mae: 32619.4316 - val_r2_score: 0.3002 - learning_rate: 0.0100\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2203287552.0000 - mae: 31541.6152 - r2_score: 0.3885 - val_loss: 2492747520.0000 - val_mae: 31994.6035 - val_r2_score: 0.2932 - learning_rate: 0.0100\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2106349568.0000 - mae: 30437.1387 - r2_score: 0.4338 - val_loss: 2333230592.0000 - val_mae: 30133.8164 - val_r2_score: 0.3384 - learning_rate: 0.0100\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1840383488.0000 - mae: 27768.3867 - r2_score: 0.4897 - val_loss: 2247305216.0000 - val_mae: 29228.6270 - val_r2_score: 0.3628 - learning_rate: 0.0100\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1912938880.0000 - mae: 28430.8555 - r2_score: 0.4966 - val_loss: 2182069248.0000 - val_mae: 28550.0820 - val_r2_score: 0.3812 - learning_rate: 0.0100\n",
      "Epoch 22/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1646699648.0000 - mae: 26548.2812 - r2_score: 0.5234 - val_loss: 2209150464.0000 - val_mae: 28340.8086 - val_r2_score: 0.3736 - learning_rate: 0.0100\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1679828096.0000 - mae: 26925.7051 - r2_score: 0.5327 - val_loss: 2041326208.0000 - val_mae: 27307.5898 - val_r2_score: 0.4212 - learning_rate: 0.0100\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1847833472.0000 - mae: 26941.8535 - r2_score: 0.5316 - val_loss: 2125960576.0000 - val_mae: 27500.7988 - val_r2_score: 0.3972 - learning_rate: 0.0100\n",
      "Epoch 25/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1591040384.0000 - mae: 26186.0801 - r2_score: 0.5579 - val_loss: 2187046656.0000 - val_mae: 27775.1797 - val_r2_score: 0.3798 - learning_rate: 0.0100\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1684298240.0000 - mae: 26528.1289 - r2_score: 0.5581 - val_loss: 2278299904.0000 - val_mae: 27853.9453 - val_r2_score: 0.3540 - learning_rate: 0.0100\n",
      "Epoch 27/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1656486272.0000 - mae: 26303.5508 - r2_score: 0.5576 - val_loss: 2082434304.0000 - val_mae: 27397.2812 - val_r2_score: 0.4095 - learning_rate: 0.0100\n",
      "Epoch 28/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1673239552.0000 - mae: 26517.1777 - r2_score: 0.5751\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1673043072.0000 - mae: 26516.4375 - r2_score: 0.5751 - val_loss: 2153083648.0000 - val_mae: 27507.7441 - val_r2_score: 0.3895 - learning_rate: 0.0100\n",
      "Epoch 29/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1417188352.0000 - mae: 25402.7051 - r2_score: 0.5829 - val_loss: 2140175104.0000 - val_mae: 27386.8789 - val_r2_score: 0.3931 - learning_rate: 0.0050\n",
      "Epoch 30/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1550486144.0000 - mae: 25603.0254 - r2_score: 0.5891 - val_loss: 2119105152.0000 - val_mae: 27201.6367 - val_r2_score: 0.3991 - learning_rate: 0.0050\n",
      "Epoch 31/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1486854656.0000 - mae: 25525.2148 - r2_score: 0.5821 - val_loss: 2161827072.0000 - val_mae: 27343.7070 - val_r2_score: 0.3870 - learning_rate: 0.0050\n",
      "Epoch 32/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1522140928.0000 - mae: 25607.1719 - r2_score: 0.5998 - val_loss: 2152726528.0000 - val_mae: 27357.9023 - val_r2_score: 0.3896 - learning_rate: 0.0050\n",
      "Epoch 33/150\n",
      "\u001b[1m269/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1452285312.0000 - mae: 25413.0762 - r2_score: 0.6044\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1453701120.0000 - mae: 25420.5117 - r2_score: 0.6042 - val_loss: 2152122112.0000 - val_mae: 27496.0605 - val_r2_score: 0.3897 - learning_rate: 0.0050\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12996201472.0000 - mae: 96724.4297 - r2_score: -2.5720 - val_loss: 12889790464.0000 - val_mae: 96483.9531 - val_r2_score: -2.4775 - learning_rate: 0.0100\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13318945792.0000 - mae: 96585.6172 - r2_score: -2.2985 - val_loss: 12383757312.0000 - val_mae: 94653.9219 - val_r2_score: -2.3410 - learning_rate: 0.0100\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12351768576.0000 - mae: 93665.2578 - r2_score: -2.2437 - val_loss: 11690945536.0000 - val_mae: 91943.1250 - val_r2_score: -2.1541 - learning_rate: 0.0100\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11911892992.0000 - mae: 91976.2578 - r2_score: -2.0681 - val_loss: 10948042752.0000 - val_mae: 89062.4453 - val_r2_score: -1.9536 - learning_rate: 0.0100\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10716704768.0000 - mae: 87112.6250 - r2_score: -1.8093 - val_loss: 9929677824.0000 - val_mae: 84420.2500 - val_r2_score: -1.6789 - learning_rate: 0.0100\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9710352384.0000 - mae: 82473.2031 - r2_score: -1.5137 - val_loss: 9085871104.0000 - val_mae: 80142.2109 - val_r2_score: -1.4513 - learning_rate: 0.0100\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8614095872.0000 - mae: 78042.4531 - r2_score: -1.3432 - val_loss: 7986017792.0000 - val_mae: 74775.1406 - val_r2_score: -1.1545 - learning_rate: 0.0100\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7460916736.0000 - mae: 72212.1172 - r2_score: -1.0499 - val_loss: 7603893248.0000 - val_mae: 72177.1172 - val_r2_score: -1.0514 - learning_rate: 0.0100\n",
      "Epoch 9/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6688946176.0000 - mae: 67317.4219 - r2_score: -0.7867 - val_loss: 6385873408.0000 - val_mae: 64730.8516 - val_r2_score: -0.7228 - learning_rate: 0.0100\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5889658880.0000 - mae: 62129.3711 - r2_score: -0.5726 - val_loss: 5689675776.0000 - val_mae: 59935.8281 - val_r2_score: -0.5350 - learning_rate: 0.0100\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5395909632.0000 - mae: 57844.7969 - r2_score: -0.3488 - val_loss: 4827337216.0000 - val_mae: 53502.7109 - val_r2_score: -0.3024 - learning_rate: 0.0100\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4334202368.0000 - mae: 51690.1797 - r2_score: -0.2045 - val_loss: 4492001792.0000 - val_mae: 51317.0625 - val_r2_score: -0.2119 - learning_rate: 0.0100\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3807935232.0000 - mae: 47534.3789 - r2_score: -0.0516 - val_loss: 4084249600.0000 - val_mae: 46805.2930 - val_r2_score: -0.1019 - learning_rate: 0.0100\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3317323520.0000 - mae: 43018.7344 - r2_score: 0.0810 - val_loss: 3686719488.0000 - val_mae: 44042.5078 - val_r2_score: 0.0054 - learning_rate: 0.0100\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3293357568.0000 - mae: 41014.8320 - r2_score: 0.1832 - val_loss: 3421697536.0000 - val_mae: 40992.1953 - val_r2_score: 0.0769 - learning_rate: 0.0100\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2637270784.0000 - mae: 36621.3672 - r2_score: 0.2949 - val_loss: 3056069632.0000 - val_mae: 37340.1289 - val_r2_score: 0.1755 - learning_rate: 0.0100\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2379849728.0000 - mae: 33827.4648 - r2_score: 0.3576 - val_loss: 2803022336.0000 - val_mae: 34897.8242 - val_r2_score: 0.2438 - learning_rate: 0.0100\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2327864576.0000 - mae: 32374.4023 - r2_score: 0.3920 - val_loss: 2425373952.0000 - val_mae: 30183.7695 - val_r2_score: 0.3457 - learning_rate: 0.0100\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2081184128.0000 - mae: 30063.2383 - r2_score: 0.4388 - val_loss: 2481666560.0000 - val_mae: 29864.4434 - val_r2_score: 0.3305 - learning_rate: 0.0100\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1858425472.0000 - mae: 28653.6055 - r2_score: 0.4770 - val_loss: 2307494656.0000 - val_mae: 28214.3691 - val_r2_score: 0.3775 - learning_rate: 0.0100\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1781222272.0000 - mae: 27535.1777 - r2_score: 0.5145 - val_loss: 2292836864.0000 - val_mae: 28147.2598 - val_r2_score: 0.3814 - learning_rate: 0.0100\n",
      "Epoch 22/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1870879360.0000 - mae: 27614.4375 - r2_score: 0.5085 - val_loss: 2202830080.0000 - val_mae: 27793.8223 - val_r2_score: 0.4057 - learning_rate: 0.0100\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1797406464.0000 - mae: 26987.0176 - r2_score: 0.5334 - val_loss: 2089881344.0000 - val_mae: 27423.2598 - val_r2_score: 0.4362 - learning_rate: 0.0100\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1619739264.0000 - mae: 26423.4727 - r2_score: 0.5428 - val_loss: 2147498496.0000 - val_mae: 27916.4375 - val_r2_score: 0.4206 - learning_rate: 0.0100\n",
      "Epoch 25/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1662980096.0000 - mae: 26637.3125 - r2_score: 0.5427 - val_loss: 2124334336.0000 - val_mae: 27188.5684 - val_r2_score: 0.4269 - learning_rate: 0.0100\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1635190016.0000 - mae: 26444.9668 - r2_score: 0.5566 - val_loss: 2103204992.0000 - val_mae: 27307.6641 - val_r2_score: 0.4326 - learning_rate: 0.0100\n",
      "Epoch 27/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1702270720.0000 - mae: 26756.3281 - r2_score: 0.5626 - val_loss: 2110108032.0000 - val_mae: 26952.6250 - val_r2_score: 0.4307 - learning_rate: 0.0100\n",
      "Epoch 28/150\n",
      "\u001b[1m265/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1619723904.0000 - mae: 26239.9531 - r2_score: 0.5622\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1620758272.0000 - mae: 26246.3516 - r2_score: 0.5622 - val_loss: 2132343424.0000 - val_mae: 27724.9590 - val_r2_score: 0.4247 - learning_rate: 0.0100\n",
      "Epoch 29/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1520946304.0000 - mae: 25701.5117 - r2_score: 0.5768 - val_loss: 2104706176.0000 - val_mae: 26905.7480 - val_r2_score: 0.4322 - learning_rate: 0.0050\n",
      "Epoch 30/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1490745984.0000 - mae: 25725.8125 - r2_score: 0.5842 - val_loss: 2111312256.0000 - val_mae: 26979.8496 - val_r2_score: 0.4304 - learning_rate: 0.0050\n",
      "Epoch 31/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1486872320.0000 - mae: 25530.6426 - r2_score: 0.5958 - val_loss: 2093943808.0000 - val_mae: 26718.9688 - val_r2_score: 0.4351 - learning_rate: 0.0050\n",
      "Epoch 32/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1451471488.0000 - mae: 25386.7188 - r2_score: 0.6104 - val_loss: 2071276288.0000 - val_mae: 26797.2168 - val_r2_score: 0.4412 - learning_rate: 0.0050\n",
      "Epoch 33/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1435254656.0000 - mae: 25010.2363 - r2_score: 0.6028 - val_loss: 2076086912.0000 - val_mae: 27525.2207 - val_r2_score: 0.4399 - learning_rate: 0.0050\n",
      "Epoch 34/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1449598976.0000 - mae: 25554.9336 - r2_score: 0.5815 - val_loss: 2079984256.0000 - val_mae: 27185.3984 - val_r2_score: 0.4388 - learning_rate: 0.0050\n",
      "Epoch 35/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1438251904.0000 - mae: 25160.8770 - r2_score: 0.6062 - val_loss: 2087137152.0000 - val_mae: 26718.9121 - val_r2_score: 0.4369 - learning_rate: 0.0050\n",
      "Epoch 36/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1454482176.0000 - mae: 25426.0605 - r2_score: 0.6089 - val_loss: 2073258880.0000 - val_mae: 27177.1484 - val_r2_score: 0.4407 - learning_rate: 0.0050\n",
      "Epoch 37/150\n",
      "\u001b[1m269/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1515485184.0000 - mae: 25676.7617 - r2_score: 0.6104\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1514145536.0000 - mae: 25672.7520 - r2_score: 0.6102 - val_loss: 2083404672.0000 - val_mae: 26627.5273 - val_r2_score: 0.4379 - learning_rate: 0.0050\n",
      "Epoch 38/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1396664576.0000 - mae: 25037.6914 - r2_score: 0.6343 - val_loss: 2053403392.0000 - val_mae: 26466.1816 - val_r2_score: 0.4460 - learning_rate: 0.0025\n",
      "Epoch 39/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1335910656.0000 - mae: 24500.8379 - r2_score: 0.6219 - val_loss: 2070653952.0000 - val_mae: 26859.1523 - val_r2_score: 0.4414 - learning_rate: 0.0025\n",
      "Epoch 40/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1455935616.0000 - mae: 25073.4395 - r2_score: 0.6320 - val_loss: 2093479680.0000 - val_mae: 26942.5391 - val_r2_score: 0.4352 - learning_rate: 0.0025\n",
      "Epoch 41/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1372833664.0000 - mae: 24970.0586 - r2_score: 0.6226 - val_loss: 2064696192.0000 - val_mae: 26551.5801 - val_r2_score: 0.4430 - learning_rate: 0.0025\n",
      "Epoch 42/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1384281856.0000 - mae: 24915.0547 - r2_score: 0.6334 - val_loss: 2040692224.0000 - val_mae: 26669.8711 - val_r2_score: 0.4494 - learning_rate: 0.0025\n",
      "Epoch 43/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1330827904.0000 - mae: 24527.8379 - r2_score: 0.6428 - val_loss: 2086943360.0000 - val_mae: 26693.5078 - val_r2_score: 0.4370 - learning_rate: 0.0025\n",
      "Epoch 44/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1373627264.0000 - mae: 24590.6719 - r2_score: 0.6255 - val_loss: 2038651648.0000 - val_mae: 27021.0371 - val_r2_score: 0.4500 - learning_rate: 0.0025\n",
      "Epoch 45/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1492290688.0000 - mae: 25208.5859 - r2_score: 0.6240 - val_loss: 2044571136.0000 - val_mae: 26446.4766 - val_r2_score: 0.4484 - learning_rate: 0.0025\n",
      "Epoch 46/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1411725312.0000 - mae: 24950.6191 - r2_score: 0.6225 - val_loss: 2060454400.0000 - val_mae: 26545.1602 - val_r2_score: 0.4441 - learning_rate: 0.0025\n",
      "Epoch 47/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1467898112.0000 - mae: 25116.3828 - r2_score: 0.6267 - val_loss: 2078761728.0000 - val_mae: 26733.9453 - val_r2_score: 0.4392 - learning_rate: 0.0025\n",
      "Epoch 48/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1387338112.0000 - mae: 24848.9902 - r2_score: 0.6303 - val_loss: 2040082432.0000 - val_mae: 26631.6387 - val_r2_score: 0.4496 - learning_rate: 0.0025\n",
      "Epoch 49/150\n",
      "\u001b[1m271/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1377905280.0000 - mae: 24679.3555 - r2_score: 0.6372\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1377422208.0000 - mae: 24681.6055 - r2_score: 0.6372 - val_loss: 2106414592.0000 - val_mae: 26581.9180 - val_r2_score: 0.4317 - learning_rate: 0.0025\n",
      "Epoch 50/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1379807488.0000 - mae: 24826.1816 - r2_score: 0.6378 - val_loss: 2075823232.0000 - val_mae: 26763.5156 - val_r2_score: 0.4400 - learning_rate: 0.0012\n",
      "Epoch 51/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1500123392.0000 - mae: 25288.3535 - r2_score: 0.6215 - val_loss: 2057168640.0000 - val_mae: 26455.5410 - val_r2_score: 0.4450 - learning_rate: 0.0012\n",
      "Epoch 52/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1346822272.0000 - mae: 24969.1680 - r2_score: 0.6418 - val_loss: 2065909504.0000 - val_mae: 26748.3672 - val_r2_score: 0.4426 - learning_rate: 0.0012\n",
      "Epoch 53/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1335153280.0000 - mae: 24563.2109 - r2_score: 0.6456 - val_loss: 2048777216.0000 - val_mae: 26634.1328 - val_r2_score: 0.4473 - learning_rate: 0.0012\n",
      "Epoch 54/150\n",
      "\u001b[1m272/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1283992832.0000 - mae: 24202.6113 - r2_score: 0.6472\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1285601920.0000 - mae: 24212.4062 - r2_score: 0.6471 - val_loss: 2067062656.0000 - val_mae: 26558.4199 - val_r2_score: 0.4423 - learning_rate: 0.0012\n",
      "Epoch 54: early stopping\n",
      "Restoring model weights from the end of the best epoch: 44.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 13196504064.0000 - mae: 97021.1641 - r2_score: -2.4925 - val_loss: 13276546048.0000 - val_mae: 97489.3828 - val_r2_score: -2.4045 - learning_rate: 0.0100\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12686713856.0000 - mae: 95088.6875 - r2_score: -2.4126 - val_loss: 12749959168.0000 - val_mae: 95587.2109 - val_r2_score: -2.2695 - learning_rate: 0.0100\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12096025600.0000 - mae: 93280.2188 - r2_score: -2.3370 - val_loss: 12061222912.0000 - val_mae: 93094.0859 - val_r2_score: -2.0929 - learning_rate: 0.0100\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11625394176.0000 - mae: 90913.1484 - r2_score: -2.0531 - val_loss: 11290082304.0000 - val_mae: 89882.1875 - val_r2_score: -1.8951 - learning_rate: 0.0100\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10690727936.0000 - mae: 86911.1484 - r2_score: -1.7870 - val_loss: 10777701376.0000 - val_mae: 87567.4219 - val_r2_score: -1.7637 - learning_rate: 0.0100\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9860005888.0000 - mae: 83008.7891 - r2_score: -1.5140 - val_loss: 9282785280.0000 - val_mae: 80027.7422 - val_r2_score: -1.3804 - learning_rate: 0.0100\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8659647488.0000 - mae: 77461.1875 - r2_score: -1.2399 - val_loss: 8369982976.0000 - val_mae: 74984.5000 - val_r2_score: -1.1463 - learning_rate: 0.0100\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7610836480.0000 - mae: 72205.5469 - r2_score: -1.0098 - val_loss: 7396088832.0000 - val_mae: 68946.0312 - val_r2_score: -0.8966 - learning_rate: 0.0100\n",
      "Epoch 9/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6464919552.0000 - mae: 66122.9922 - r2_score: -0.7740 - val_loss: 7073587712.0000 - val_mae: 66902.9219 - val_r2_score: -0.8139 - learning_rate: 0.0100\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5770648064.0000 - mae: 61574.2266 - r2_score: -0.5646 - val_loss: 6020889088.0000 - val_mae: 60295.3438 - val_r2_score: -0.5439 - learning_rate: 0.0100\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5034479616.0000 - mae: 56635.6172 - r2_score: -0.3558 - val_loss: 5431869440.0000 - val_mae: 56644.5781 - val_r2_score: -0.3929 - learning_rate: 0.0100\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4515472896.0000 - mae: 52313.5469 - r2_score: -0.1832 - val_loss: 4439780352.0000 - val_mae: 49585.8633 - val_r2_score: -0.1385 - learning_rate: 0.0100\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3938791936.0000 - mae: 48181.9023 - r2_score: -0.0456 - val_loss: 4201775616.0000 - val_mae: 47811.9883 - val_r2_score: -0.0775 - learning_rate: 0.0100\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3591104512.0000 - mae: 43807.3906 - r2_score: 0.1102 - val_loss: 3883241728.0000 - val_mae: 44590.4805 - val_r2_score: 0.0042 - learning_rate: 0.0100\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2979598336.0000 - mae: 39694.3203 - r2_score: 0.2116 - val_loss: 3486056704.0000 - val_mae: 41036.8047 - val_r2_score: 0.1061 - learning_rate: 0.0100\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2742686464.0000 - mae: 36859.1445 - r2_score: 0.2927 - val_loss: 3049828096.0000 - val_mae: 36733.3281 - val_r2_score: 0.2179 - learning_rate: 0.0100\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2391002880.0000 - mae: 33827.6875 - r2_score: 0.3561 - val_loss: 2829375488.0000 - val_mae: 33973.9570 - val_r2_score: 0.2745 - learning_rate: 0.0100\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2174558464.0000 - mae: 31684.9668 - r2_score: 0.3993 - val_loss: 2747249152.0000 - val_mae: 31941.8457 - val_r2_score: 0.2955 - learning_rate: 0.0100\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2135754880.0000 - mae: 30342.7676 - r2_score: 0.4318 - val_loss: 2503677696.0000 - val_mae: 30998.6797 - val_r2_score: 0.3580 - learning_rate: 0.0100\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2079836544.0000 - mae: 29153.8086 - r2_score: 0.4576 - val_loss: 2494884096.0000 - val_mae: 30015.9375 - val_r2_score: 0.3602 - learning_rate: 0.0100\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2057561984.0000 - mae: 28777.2676 - r2_score: 0.4903 - val_loss: 2404655616.0000 - val_mae: 29064.5566 - val_r2_score: 0.3834 - learning_rate: 0.0100\n",
      "Epoch 22/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2012598272.0000 - mae: 27918.6855 - r2_score: 0.5092 - val_loss: 2322342144.0000 - val_mae: 27874.0117 - val_r2_score: 0.4045 - learning_rate: 0.0100\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1929549952.0000 - mae: 27267.6816 - r2_score: 0.5189 - val_loss: 2329652480.0000 - val_mae: 27782.2969 - val_r2_score: 0.4026 - learning_rate: 0.0100\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1687566848.0000 - mae: 26815.2266 - r2_score: 0.5477 - val_loss: 2337996288.0000 - val_mae: 28244.2129 - val_r2_score: 0.4005 - learning_rate: 0.0100\n",
      "Epoch 25/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1743380736.0000 - mae: 26707.4102 - r2_score: 0.5408 - val_loss: 2313168896.0000 - val_mae: 27906.1504 - val_r2_score: 0.4068 - learning_rate: 0.0100\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1709842048.0000 - mae: 26307.8145 - r2_score: 0.5470 - val_loss: 2283718400.0000 - val_mae: 27546.8008 - val_r2_score: 0.4144 - learning_rate: 0.0100\n",
      "Epoch 27/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1687384960.0000 - mae: 26672.4688 - r2_score: 0.5547 - val_loss: 2357508096.0000 - val_mae: 27933.8398 - val_r2_score: 0.3955 - learning_rate: 0.0100\n",
      "Epoch 28/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1622510976.0000 - mae: 26145.6719 - r2_score: 0.5560 - val_loss: 2343824640.0000 - val_mae: 27790.8086 - val_r2_score: 0.3990 - learning_rate: 0.0100\n",
      "Epoch 29/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1622451840.0000 - mae: 26012.8457 - r2_score: 0.5670 - val_loss: 2339110656.0000 - val_mae: 27845.4824 - val_r2_score: 0.4002 - learning_rate: 0.0100\n",
      "Epoch 30/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1710985344.0000 - mae: 26645.0879 - r2_score: 0.5588 - val_loss: 2297178368.0000 - val_mae: 27596.2891 - val_r2_score: 0.4109 - learning_rate: 0.0100\n",
      "Epoch 31/150\n",
      "\u001b[1m277/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1642102016.0000 - mae: 26469.2598 - r2_score: 0.5678\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1642329984.0000 - mae: 26468.8320 - r2_score: 0.5678 - val_loss: 2347816704.0000 - val_mae: 28214.4258 - val_r2_score: 0.3980 - learning_rate: 0.0100\n",
      "Epoch 32/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1615167104.0000 - mae: 26137.0586 - r2_score: 0.5630 - val_loss: 2336301568.0000 - val_mae: 27773.3242 - val_r2_score: 0.4009 - learning_rate: 0.0050\n",
      "Epoch 33/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1628080128.0000 - mae: 26285.2480 - r2_score: 0.5913 - val_loss: 2365080576.0000 - val_mae: 27629.0234 - val_r2_score: 0.3935 - learning_rate: 0.0050\n",
      "Epoch 34/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1541655808.0000 - mae: 25962.1562 - r2_score: 0.5956 - val_loss: 2336583680.0000 - val_mae: 27720.6992 - val_r2_score: 0.4008 - learning_rate: 0.0050\n",
      "Epoch 35/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1701127808.0000 - mae: 26199.9023 - r2_score: 0.5768 - val_loss: 2375955456.0000 - val_mae: 27697.8359 - val_r2_score: 0.3907 - learning_rate: 0.0050\n",
      "Epoch 36/150\n",
      "\u001b[1m272/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1363578112.0000 - mae: 25025.0176 - r2_score: 0.6120\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1368912256.0000 - mae: 25043.4961 - r2_score: 0.6115 - val_loss: 2379355392.0000 - val_mae: 27921.2773 - val_r2_score: 0.3899 - learning_rate: 0.0050\n",
      "Epoch 36: early stopping\n",
      "Restoring model weights from the end of the best epoch: 26.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 13325169664.0000 - mae: 97049.1641 - r2_score: -2.4165 - val_loss: 13211247616.0000 - val_mae: 97270.7266 - val_r2_score: -2.4028 - learning_rate: 0.0100\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 13083843584.0000 - mae: 96092.8125 - r2_score: -2.3337 - val_loss: 12769687552.0000 - val_mae: 95821.2109 - val_r2_score: -2.2890 - learning_rate: 0.0100\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12349104128.0000 - mae: 93653.5234 - r2_score: -2.2441 - val_loss: 11825613824.0000 - val_mae: 92231.6250 - val_r2_score: -2.0459 - learning_rate: 0.0100\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11720422400.0000 - mae: 91155.7812 - r2_score: -2.0402 - val_loss: 11241225216.0000 - val_mae: 89605.2266 - val_r2_score: -1.8954 - learning_rate: 0.0100\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 10578310144.0000 - mae: 86553.6562 - r2_score: -1.8129 - val_loss: 10111719424.0000 - val_mae: 84555.4062 - val_r2_score: -1.6044 - learning_rate: 0.0100\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 9731372032.0000 - mae: 82649.5312 - r2_score: -1.5508 - val_loss: 9390083072.0000 - val_mae: 80816.8906 - val_r2_score: -1.4186 - learning_rate: 0.0100\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8944471040.0000 - mae: 78025.5938 - r2_score: -1.2253 - val_loss: 8173607936.0000 - val_mae: 74411.9219 - val_r2_score: -1.1052 - learning_rate: 0.0100\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7555488768.0000 - mae: 72791.8672 - r2_score: -1.0974 - val_loss: 7833029632.0000 - val_mae: 70888.4766 - val_r2_score: -1.0175 - learning_rate: 0.0100\n",
      "Epoch 9/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6655717376.0000 - mae: 67744.7969 - r2_score: -0.8518 - val_loss: 6407696896.0000 - val_mae: 63027.5625 - val_r2_score: -0.6504 - learning_rate: 0.0100\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6101138944.0000 - mae: 62644.0742 - r2_score: -0.5682 - val_loss: 6053270528.0000 - val_mae: 60729.5820 - val_r2_score: -0.5591 - learning_rate: 0.0100\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5265936384.0000 - mae: 57498.5781 - r2_score: -0.3678 - val_loss: 5430248448.0000 - val_mae: 56931.6953 - val_r2_score: -0.3986 - learning_rate: 0.0100\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4666517504.0000 - mae: 53003.7539 - r2_score: -0.2049 - val_loss: 4535497216.0000 - val_mae: 51426.8359 - val_r2_score: -0.1682 - learning_rate: 0.0100\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3978464256.0000 - mae: 47982.1914 - r2_score: -0.0442 - val_loss: 4174231552.0000 - val_mae: 47784.3516 - val_r2_score: -0.0751 - learning_rate: 0.0100\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3353800192.0000 - mae: 43554.2734 - r2_score: 0.0759 - val_loss: 3704959488.0000 - val_mae: 43948.2305 - val_r2_score: 0.0457 - learning_rate: 0.0100\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3218942720.0000 - mae: 40700.7422 - r2_score: 0.1841 - val_loss: 3195970816.0000 - val_mae: 38585.4102 - val_r2_score: 0.1768 - learning_rate: 0.0100\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2733826304.0000 - mae: 37048.2148 - r2_score: 0.2839 - val_loss: 3069002496.0000 - val_mae: 37436.7500 - val_r2_score: 0.2095 - learning_rate: 0.0100\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2543458560.0000 - mae: 34279.2656 - r2_score: 0.3363 - val_loss: 2837948160.0000 - val_mae: 33890.0234 - val_r2_score: 0.2690 - learning_rate: 0.0100\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2458506752.0000 - mae: 32605.3496 - r2_score: 0.3868 - val_loss: 2748154368.0000 - val_mae: 32357.5117 - val_r2_score: 0.2922 - learning_rate: 0.0100\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2047211392.0000 - mae: 30038.0957 - r2_score: 0.4285 - val_loss: 2439249920.0000 - val_mae: 29086.1309 - val_r2_score: 0.3717 - learning_rate: 0.0100\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2017177216.0000 - mae: 28966.9688 - r2_score: 0.4651 - val_loss: 2496804096.0000 - val_mae: 29541.4336 - val_r2_score: 0.3569 - learning_rate: 0.0100\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1928210176.0000 - mae: 28063.2461 - r2_score: 0.4945 - val_loss: 2442068992.0000 - val_mae: 29172.8340 - val_r2_score: 0.3710 - learning_rate: 0.0100\n",
      "Epoch 22/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1812746368.0000 - mae: 27492.9609 - r2_score: 0.5159 - val_loss: 2329678592.0000 - val_mae: 28057.1035 - val_r2_score: 0.4000 - learning_rate: 0.0100\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1869152768.0000 - mae: 27578.2305 - r2_score: 0.5137 - val_loss: 2397735680.0000 - val_mae: 28258.7480 - val_r2_score: 0.3824 - learning_rate: 0.0100\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1757707776.0000 - mae: 27060.3906 - r2_score: 0.5530 - val_loss: 2303342080.0000 - val_mae: 27946.7930 - val_r2_score: 0.4067 - learning_rate: 0.0100\n",
      "Epoch 25/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1805854976.0000 - mae: 26820.2383 - r2_score: 0.5338 - val_loss: 2306638592.0000 - val_mae: 27666.0234 - val_r2_score: 0.4059 - learning_rate: 0.0100\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1682202624.0000 - mae: 26858.4258 - r2_score: 0.5507 - val_loss: 2307315456.0000 - val_mae: 27698.8438 - val_r2_score: 0.4057 - learning_rate: 0.0100\n",
      "Epoch 27/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1568492160.0000 - mae: 26587.6582 - r2_score: 0.5688 - val_loss: 2347788800.0000 - val_mae: 28927.1973 - val_r2_score: 0.3953 - learning_rate: 0.0100\n",
      "Epoch 28/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1727821568.0000 - mae: 26835.7773 - r2_score: 0.5565 - val_loss: 2270486528.0000 - val_mae: 27868.4766 - val_r2_score: 0.4152 - learning_rate: 0.0100\n",
      "Epoch 29/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1678114432.0000 - mae: 26505.7656 - r2_score: 0.5530 - val_loss: 2346771968.0000 - val_mae: 28509.0020 - val_r2_score: 0.3956 - learning_rate: 0.0100\n",
      "Epoch 30/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1647377280.0000 - mae: 26580.9277 - r2_score: 0.5733 - val_loss: 2236722944.0000 - val_mae: 27247.2090 - val_r2_score: 0.4239 - learning_rate: 0.0100\n",
      "Epoch 31/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1475339904.0000 - mae: 25859.5098 - r2_score: 0.5926 - val_loss: 2417129984.0000 - val_mae: 28543.2363 - val_r2_score: 0.3774 - learning_rate: 0.0100\n",
      "Epoch 32/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1594265344.0000 - mae: 26260.8379 - r2_score: 0.5844 - val_loss: 2400188928.0000 - val_mae: 27548.5684 - val_r2_score: 0.3818 - learning_rate: 0.0100\n",
      "Epoch 33/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1732113024.0000 - mae: 26722.1484 - r2_score: 0.5710 - val_loss: 2275226112.0000 - val_mae: 27731.6543 - val_r2_score: 0.4140 - learning_rate: 0.0100\n",
      "Epoch 34/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1502771072.0000 - mae: 25760.6191 - r2_score: 0.5740 - val_loss: 2424922112.0000 - val_mae: 27770.2832 - val_r2_score: 0.3754 - learning_rate: 0.0100\n",
      "Epoch 35/150\n",
      "\u001b[1m263/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1582588416.0000 - mae: 26509.2227 - r2_score: 0.5905\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1584116480.0000 - mae: 26512.4219 - r2_score: 0.5897 - val_loss: 2330610688.0000 - val_mae: 27814.3828 - val_r2_score: 0.3997 - learning_rate: 0.0100\n",
      "Epoch 36/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1709723136.0000 - mae: 26620.8398 - r2_score: 0.5866 - val_loss: 2278349824.0000 - val_mae: 27723.6465 - val_r2_score: 0.4132 - learning_rate: 0.0050\n",
      "Epoch 37/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1555831552.0000 - mae: 26096.2051 - r2_score: 0.6006 - val_loss: 2242324992.0000 - val_mae: 28036.8809 - val_r2_score: 0.4225 - learning_rate: 0.0050\n",
      "Epoch 38/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1437930496.0000 - mae: 25419.3594 - r2_score: 0.6221 - val_loss: 2296495104.0000 - val_mae: 27575.4492 - val_r2_score: 0.4085 - learning_rate: 0.0050\n",
      "Epoch 39/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1562419072.0000 - mae: 25722.9590 - r2_score: 0.6125 - val_loss: 2270952960.0000 - val_mae: 27490.2402 - val_r2_score: 0.4151 - learning_rate: 0.0050\n",
      "Epoch 40/150\n",
      "\u001b[1m271/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1459636096.0000 - mae: 25679.9785 - r2_score: 0.6089\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1460978432.0000 - mae: 25685.0195 - r2_score: 0.6088 - val_loss: 2252559872.0000 - val_mae: 27300.6836 - val_r2_score: 0.4198 - learning_rate: 0.0050\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 12883798016.0000 - mae: 95762.0312 - r2_score: -2.3919 - val_loss: 8708877312.0000 - val_mae: 80347.8203 - val_r2_score: -1.2830 - learning_rate: 0.0500\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8596924416.0000 - mae: 76034.4297 - r2_score: -1.2317 - val_loss: 5853385216.0000 - val_mae: 61444.9844 - val_r2_score: -0.5344 - learning_rate: 0.0500\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4367241216.0000 - mae: 48143.7773 - r2_score: -0.1273 - val_loss: 3471988480.0000 - val_mae: 38372.0547 - val_r2_score: 0.0898 - learning_rate: 0.0500\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2964539392.0000 - mae: 33592.5469 - r2_score: 0.2711 - val_loss: 2845668608.0000 - val_mae: 29297.5410 - val_r2_score: 0.2540 - learning_rate: 0.0500\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2372568832.0000 - mae: 29371.1836 - r2_score: 0.3798 - val_loss: 2913896960.0000 - val_mae: 28391.1152 - val_r2_score: 0.2361 - learning_rate: 0.0500\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2218352896.0000 - mae: 28806.8359 - r2_score: 0.4209 - val_loss: 4018167552.0000 - val_mae: 28791.8848 - val_r2_score: -0.0533 - learning_rate: 0.0500\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2385445632.0000 - mae: 29326.8848 - r2_score: 0.4078 - val_loss: 2835046400.0000 - val_mae: 28073.0508 - val_r2_score: 0.2568 - learning_rate: 0.0500\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2328700928.0000 - mae: 28676.4551 - r2_score: 0.4150 - val_loss: 3040785664.0000 - val_mae: 28328.2617 - val_r2_score: 0.2029 - learning_rate: 0.0500\n",
      "Epoch 9/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2283657984.0000 - mae: 28525.3242 - r2_score: 0.4304 - val_loss: 3633076736.0000 - val_mae: 29520.4766 - val_r2_score: 0.0476 - learning_rate: 0.0500\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2268567552.0000 - mae: 29155.2812 - r2_score: 0.4424 - val_loss: 2507439360.0000 - val_mae: 27928.9004 - val_r2_score: 0.3427 - learning_rate: 0.0500\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2018793728.0000 - mae: 27984.5215 - r2_score: 0.4448 - val_loss: 2976021248.0000 - val_mae: 28927.7051 - val_r2_score: 0.2198 - learning_rate: 0.0500\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2019345664.0000 - mae: 28277.2559 - r2_score: 0.4534 - val_loss: 2491718912.0000 - val_mae: 28015.4590 - val_r2_score: 0.3468 - learning_rate: 0.0500\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2089097728.0000 - mae: 28122.7734 - r2_score: 0.4490 - val_loss: 2220662528.0000 - val_mae: 27829.3887 - val_r2_score: 0.4179 - learning_rate: 0.0500\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2157955072.0000 - mae: 28602.9746 - r2_score: 0.4490 - val_loss: 2146916096.0000 - val_mae: 28305.7656 - val_r2_score: 0.4372 - learning_rate: 0.0500\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2075605888.0000 - mae: 28192.4453 - r2_score: 0.4658 - val_loss: 2225103104.0000 - val_mae: 27962.2422 - val_r2_score: 0.4167 - learning_rate: 0.0500\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2007315200.0000 - mae: 28139.0156 - r2_score: 0.4625 - val_loss: 2227405056.0000 - val_mae: 28152.4102 - val_r2_score: 0.4161 - learning_rate: 0.0500\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2011924096.0000 - mae: 28401.6582 - r2_score: 0.4623 - val_loss: 2279616256.0000 - val_mae: 27829.1172 - val_r2_score: 0.4024 - learning_rate: 0.0500\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2054742400.0000 - mae: 28176.5566 - r2_score: 0.4671 - val_loss: 2161151488.0000 - val_mae: 27772.7090 - val_r2_score: 0.4335 - learning_rate: 0.0500\n",
      "Epoch 19/150\n",
      "\u001b[1m269/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2095070592.0000 - mae: 27828.5684 - r2_score: 0.4851\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2092770176.0000 - mae: 27845.9766 - r2_score: 0.4846 - val_loss: 2178505216.0000 - val_mae: 27567.1738 - val_r2_score: 0.4289 - learning_rate: 0.0500\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1944522752.0000 - mae: 27948.9766 - r2_score: 0.4964 - val_loss: 2226758912.0000 - val_mae: 28190.5020 - val_r2_score: 0.4163 - learning_rate: 0.0250\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1842261760.0000 - mae: 27440.5605 - r2_score: 0.5146 - val_loss: 2167880448.0000 - val_mae: 27748.1895 - val_r2_score: 0.4317 - learning_rate: 0.0250\n",
      "Epoch 22/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1781214208.0000 - mae: 27059.1836 - r2_score: 0.5226 - val_loss: 2164281344.0000 - val_mae: 27309.0391 - val_r2_score: 0.4326 - learning_rate: 0.0250\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1771546240.0000 - mae: 27001.9355 - r2_score: 0.5265 - val_loss: 2233439488.0000 - val_mae: 27879.9434 - val_r2_score: 0.4145 - learning_rate: 0.0250\n",
      "Epoch 24/150\n",
      "\u001b[1m265/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1896012032.0000 - mae: 27451.7168 - r2_score: 0.5182\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1895710208.0000 - mae: 27463.6191 - r2_score: 0.5178 - val_loss: 2161256448.0000 - val_mae: 27727.7852 - val_r2_score: 0.4334 - learning_rate: 0.0250\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 14.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 13064833024.0000 - mae: 95976.4297 - r2_score: -2.3280 - val_loss: 8194099200.0000 - val_mae: 78301.5938 - val_r2_score: -1.3235 - learning_rate: 0.0500\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8555938816.0000 - mae: 76294.8125 - r2_score: -1.2856 - val_loss: 5831971328.0000 - val_mae: 62279.1016 - val_r2_score: -0.6537 - learning_rate: 0.0500\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4147286528.0000 - mae: 47963.6289 - r2_score: -0.1373 - val_loss: 3666799104.0000 - val_mae: 42293.4258 - val_r2_score: -0.0398 - learning_rate: 0.0500\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2454778624.0000 - mae: 32689.0957 - r2_score: 0.3109 - val_loss: 2631575296.0000 - val_mae: 30209.2832 - val_r2_score: 0.2538 - learning_rate: 0.0500\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2359911936.0000 - mae: 29722.5957 - r2_score: 0.3729 - val_loss: 2609703680.0000 - val_mae: 28221.6973 - val_r2_score: 0.2600 - learning_rate: 0.0500\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2196437504.0000 - mae: 28881.9980 - r2_score: 0.4055 - val_loss: 2577188864.0000 - val_mae: 28097.2148 - val_r2_score: 0.2692 - learning_rate: 0.0500\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2253938176.0000 - mae: 28771.3516 - r2_score: 0.4005 - val_loss: 2408150528.0000 - val_mae: 27901.9961 - val_r2_score: 0.3171 - learning_rate: 0.0500\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2070074112.0000 - mae: 28711.9355 - r2_score: 0.4307 - val_loss: 2432853248.0000 - val_mae: 28026.4102 - val_r2_score: 0.3101 - learning_rate: 0.0500\n",
      "Epoch 9/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2026708096.0000 - mae: 28007.1934 - r2_score: 0.4315 - val_loss: 2472819968.0000 - val_mae: 28179.3340 - val_r2_score: 0.2988 - learning_rate: 0.0500\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1990639360.0000 - mae: 28398.4160 - r2_score: 0.4349 - val_loss: 2337147136.0000 - val_mae: 27713.1699 - val_r2_score: 0.3373 - learning_rate: 0.0500\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2123827584.0000 - mae: 28639.4316 - r2_score: 0.4245 - val_loss: 2358658560.0000 - val_mae: 27939.2129 - val_r2_score: 0.3312 - learning_rate: 0.0500\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2118581632.0000 - mae: 28365.8418 - r2_score: 0.4437 - val_loss: 2026932480.0000 - val_mae: 27635.6523 - val_r2_score: 0.4252 - learning_rate: 0.0500\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1924384512.0000 - mae: 27633.3223 - r2_score: 0.4585 - val_loss: 1996143232.0000 - val_mae: 27203.7402 - val_r2_score: 0.4340 - learning_rate: 0.0500\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2057323392.0000 - mae: 28151.7930 - r2_score: 0.4549 - val_loss: 1982237568.0000 - val_mae: 27578.5605 - val_r2_score: 0.4379 - learning_rate: 0.0500\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1992345472.0000 - mae: 27677.2188 - r2_score: 0.4603 - val_loss: 1994526208.0000 - val_mae: 28060.2090 - val_r2_score: 0.4344 - learning_rate: 0.0500\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1833089280.0000 - mae: 27158.0293 - r2_score: 0.4880 - val_loss: 2030426880.0000 - val_mae: 27652.6055 - val_r2_score: 0.4242 - learning_rate: 0.0500\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1994483200.0000 - mae: 27915.0859 - r2_score: 0.4667 - val_loss: 1977936256.0000 - val_mae: 28195.3633 - val_r2_score: 0.4391 - learning_rate: 0.0500\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2036307328.0000 - mae: 28059.7012 - r2_score: 0.4725 - val_loss: 1992739456.0000 - val_mae: 27066.4980 - val_r2_score: 0.4349 - learning_rate: 0.0500\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2029441920.0000 - mae: 28012.3145 - r2_score: 0.4746 - val_loss: 1996736128.0000 - val_mae: 27085.5488 - val_r2_score: 0.4338 - learning_rate: 0.0500\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1780036352.0000 - mae: 27070.3301 - r2_score: 0.5007 - val_loss: 1937228288.0000 - val_mae: 27300.6758 - val_r2_score: 0.4507 - learning_rate: 0.0500\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1899735552.0000 - mae: 27456.0059 - r2_score: 0.4862 - val_loss: 1995063424.0000 - val_mae: 27374.7207 - val_r2_score: 0.4343 - learning_rate: 0.0500\n",
      "Epoch 22/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1885969920.0000 - mae: 27490.2812 - r2_score: 0.4841 - val_loss: 2148532480.0000 - val_mae: 28363.0059 - val_r2_score: 0.3908 - learning_rate: 0.0500\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1994017408.0000 - mae: 28398.2246 - r2_score: 0.4753 - val_loss: 2087405824.0000 - val_mae: 28419.4199 - val_r2_score: 0.4081 - learning_rate: 0.0500\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1806541440.0000 - mae: 27635.4160 - r2_score: 0.5017 - val_loss: 2001470208.0000 - val_mae: 27602.1504 - val_r2_score: 0.4325 - learning_rate: 0.0500\n",
      "Epoch 25/150\n",
      "\u001b[1m267/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1847174016.0000 - mae: 27544.0820 - r2_score: 0.5117\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1849046528.0000 - mae: 27551.0078 - r2_score: 0.5108 - val_loss: 1966719488.0000 - val_mae: 27220.8262 - val_r2_score: 0.4423 - learning_rate: 0.0500\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1787896192.0000 - mae: 26698.1973 - r2_score: 0.5136 - val_loss: 1976311936.0000 - val_mae: 27056.9531 - val_r2_score: 0.4396 - learning_rate: 0.0250\n",
      "Epoch 27/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1672010752.0000 - mae: 26415.6680 - r2_score: 0.5367 - val_loss: 1921448320.0000 - val_mae: 27079.9219 - val_r2_score: 0.4552 - learning_rate: 0.0250\n",
      "Epoch 28/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1629200768.0000 - mae: 26362.3672 - r2_score: 0.5501 - val_loss: 1972800768.0000 - val_mae: 27069.2793 - val_r2_score: 0.4406 - learning_rate: 0.0250\n",
      "Epoch 29/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1695343744.0000 - mae: 26555.8340 - r2_score: 0.5433 - val_loss: 1999075328.0000 - val_mae: 27293.0137 - val_r2_score: 0.4331 - learning_rate: 0.0250\n",
      "Epoch 30/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1660010752.0000 - mae: 26687.3262 - r2_score: 0.5517 - val_loss: 2010128000.0000 - val_mae: 27566.7559 - val_r2_score: 0.4300 - learning_rate: 0.0250\n",
      "Epoch 31/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1684625152.0000 - mae: 26304.5723 - r2_score: 0.5625 - val_loss: 1972998144.0000 - val_mae: 27273.4590 - val_r2_score: 0.4405 - learning_rate: 0.0250\n",
      "Epoch 32/150\n",
      "\u001b[1m266/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1666295936.0000 - mae: 26495.5742 - r2_score: 0.5556\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1667152256.0000 - mae: 26498.6816 - r2_score: 0.5552 - val_loss: 1987038336.0000 - val_mae: 26943.8047 - val_r2_score: 0.4366 - learning_rate: 0.0250\n",
      "Epoch 33/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1504429952.0000 - mae: 25431.2051 - r2_score: 0.5778 - val_loss: 1974678912.0000 - val_mae: 26923.4883 - val_r2_score: 0.4401 - learning_rate: 0.0125\n",
      "Epoch 34/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1534200704.0000 - mae: 25799.3691 - r2_score: 0.5825 - val_loss: 2026985344.0000 - val_mae: 27509.9531 - val_r2_score: 0.4252 - learning_rate: 0.0125\n",
      "Epoch 35/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1516784128.0000 - mae: 25688.7383 - r2_score: 0.5876 - val_loss: 1963046144.0000 - val_mae: 27112.8418 - val_r2_score: 0.4434 - learning_rate: 0.0125\n",
      "Epoch 36/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1507795584.0000 - mae: 25695.4238 - r2_score: 0.5971 - val_loss: 2042651136.0000 - val_mae: 27383.9023 - val_r2_score: 0.4208 - learning_rate: 0.0125\n",
      "Epoch 37/150\n",
      "\u001b[1m266/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1569676800.0000 - mae: 25765.6504 - r2_score: 0.5921\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1566545280.0000 - mae: 25759.9824 - r2_score: 0.5921 - val_loss: 1975959168.0000 - val_mae: 27140.0742 - val_r2_score: 0.4397 - learning_rate: 0.0125\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 13042584576.0000 - mae: 95834.1406 - r2_score: -2.3282 - val_loss: 9431491584.0000 - val_mae: 84624.7891 - val_r2_score: -1.5445 - learning_rate: 0.0500\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8623779840.0000 - mae: 76178.0312 - r2_score: -1.2289 - val_loss: 4734878208.0000 - val_mae: 53510.3398 - val_r2_score: -0.2774 - learning_rate: 0.0500\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4481769472.0000 - mae: 48945.7969 - r2_score: -0.1390 - val_loss: 3240568064.0000 - val_mae: 38196.1562 - val_r2_score: 0.1257 - learning_rate: 0.0500\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2740459520.0000 - mae: 33160.1992 - r2_score: 0.2751 - val_loss: 2764777728.0000 - val_mae: 32189.3750 - val_r2_score: 0.2541 - learning_rate: 0.0500\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2352696832.0000 - mae: 29854.6562 - r2_score: 0.3701 - val_loss: 2394332416.0000 - val_mae: 27905.1387 - val_r2_score: 0.3540 - learning_rate: 0.0500\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2116536448.0000 - mae: 28959.9746 - r2_score: 0.4101 - val_loss: 2242391552.0000 - val_mae: 27646.1582 - val_r2_score: 0.3950 - learning_rate: 0.0500\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2145485952.0000 - mae: 28685.4277 - r2_score: 0.4186 - val_loss: 2395342080.0000 - val_mae: 27598.0176 - val_r2_score: 0.3538 - learning_rate: 0.0500\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2130036352.0000 - mae: 29205.7324 - r2_score: 0.4147 - val_loss: 2518070272.0000 - val_mae: 28444.8535 - val_r2_score: 0.3207 - learning_rate: 0.0500\n",
      "Epoch 9/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2304758272.0000 - mae: 29380.0605 - r2_score: 0.4133 - val_loss: 2284666624.0000 - val_mae: 27590.0723 - val_r2_score: 0.3836 - learning_rate: 0.0500\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2214264832.0000 - mae: 28897.9922 - r2_score: 0.4178 - val_loss: 2231194624.0000 - val_mae: 27703.5684 - val_r2_score: 0.3981 - learning_rate: 0.0500\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2027772800.0000 - mae: 28600.9375 - r2_score: 0.4509 - val_loss: 2183849984.0000 - val_mae: 27420.6250 - val_r2_score: 0.4108 - learning_rate: 0.0500\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2156510464.0000 - mae: 28366.8301 - r2_score: 0.4512 - val_loss: 2130025216.0000 - val_mae: 27450.0176 - val_r2_score: 0.4253 - learning_rate: 0.0500\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2106641920.0000 - mae: 28551.7793 - r2_score: 0.4586 - val_loss: 2148346624.0000 - val_mae: 27081.8496 - val_r2_score: 0.4204 - learning_rate: 0.0500\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2140451200.0000 - mae: 28417.7266 - r2_score: 0.4511 - val_loss: 2102101632.0000 - val_mae: 27813.7305 - val_r2_score: 0.4329 - learning_rate: 0.0500\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2058159872.0000 - mae: 28196.1348 - r2_score: 0.4551 - val_loss: 2193297152.0000 - val_mae: 27705.7910 - val_r2_score: 0.4083 - learning_rate: 0.0500\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1995341824.0000 - mae: 27971.6797 - r2_score: 0.4747 - val_loss: 2122728576.0000 - val_mae: 27442.1113 - val_r2_score: 0.4273 - learning_rate: 0.0500\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1862623744.0000 - mae: 27946.1680 - r2_score: 0.4794 - val_loss: 2093817088.0000 - val_mae: 27104.0918 - val_r2_score: 0.4351 - learning_rate: 0.0500\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1864108928.0000 - mae: 27836.3398 - r2_score: 0.4834 - val_loss: 2135920384.0000 - val_mae: 27863.5293 - val_r2_score: 0.4238 - learning_rate: 0.0500\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1968464640.0000 - mae: 28114.2402 - r2_score: 0.4852 - val_loss: 2133671168.0000 - val_mae: 27308.4473 - val_r2_score: 0.4244 - learning_rate: 0.0500\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1953296384.0000 - mae: 27992.2793 - r2_score: 0.4807 - val_loss: 2097606528.0000 - val_mae: 27170.3750 - val_r2_score: 0.4341 - learning_rate: 0.0500\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1975712768.0000 - mae: 27830.8828 - r2_score: 0.4912 - val_loss: 2154376448.0000 - val_mae: 27158.3496 - val_r2_score: 0.4188 - learning_rate: 0.0500\n",
      "Epoch 22/150\n",
      "\u001b[1m270/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2030882048.0000 - mae: 28415.5645 - r2_score: 0.4894\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2026630528.0000 - mae: 28401.0625 - r2_score: 0.4895 - val_loss: 2114899328.0000 - val_mae: 28022.9707 - val_r2_score: 0.4294 - learning_rate: 0.0500\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1869358592.0000 - mae: 27236.8965 - r2_score: 0.5046 - val_loss: 2062821888.0000 - val_mae: 27232.0664 - val_r2_score: 0.4435 - learning_rate: 0.0250\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1752655232.0000 - mae: 27245.2363 - r2_score: 0.5272 - val_loss: 2089710720.0000 - val_mae: 27029.3672 - val_r2_score: 0.4362 - learning_rate: 0.0250\n",
      "Epoch 25/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1820278144.0000 - mae: 27078.8867 - r2_score: 0.5283 - val_loss: 2143858304.0000 - val_mae: 27348.2891 - val_r2_score: 0.4216 - learning_rate: 0.0250\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1732997632.0000 - mae: 26960.3887 - r2_score: 0.5286 - val_loss: 2172640000.0000 - val_mae: 27375.6074 - val_r2_score: 0.4138 - learning_rate: 0.0250\n",
      "Epoch 27/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1637825408.0000 - mae: 26575.6094 - r2_score: 0.5500 - val_loss: 2152719360.0000 - val_mae: 27810.5059 - val_r2_score: 0.4192 - learning_rate: 0.0250\n",
      "Epoch 28/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1744242176.0000 - mae: 26752.2109 - r2_score: 0.5388 - val_loss: 2062135808.0000 - val_mae: 27946.5371 - val_r2_score: 0.4437 - learning_rate: 0.0250\n",
      "Epoch 29/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1763035776.0000 - mae: 26964.3887 - r2_score: 0.5415 - val_loss: 2061691520.0000 - val_mae: 27328.6289 - val_r2_score: 0.4438 - learning_rate: 0.0250\n",
      "Epoch 30/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1695292544.0000 - mae: 26749.3867 - r2_score: 0.5471 - val_loss: 2181390592.0000 - val_mae: 27363.9180 - val_r2_score: 0.4115 - learning_rate: 0.0250\n",
      "Epoch 31/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1685834112.0000 - mae: 26603.5684 - r2_score: 0.5537 - val_loss: 2060318592.0000 - val_mae: 27182.1309 - val_r2_score: 0.4442 - learning_rate: 0.0250\n",
      "Epoch 32/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1641922560.0000 - mae: 26747.5020 - r2_score: 0.5469 - val_loss: 2088930304.0000 - val_mae: 27437.3887 - val_r2_score: 0.4364 - learning_rate: 0.0250\n",
      "Epoch 33/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1590162944.0000 - mae: 26243.1309 - r2_score: 0.5822 - val_loss: 2071822592.0000 - val_mae: 27961.0508 - val_r2_score: 0.4410 - learning_rate: 0.0250\n",
      "Epoch 34/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1624360832.0000 - mae: 26218.9004 - r2_score: 0.5669 - val_loss: 2147416448.0000 - val_mae: 28480.8164 - val_r2_score: 0.4207 - learning_rate: 0.0250\n",
      "Epoch 35/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1574068736.0000 - mae: 26190.8555 - r2_score: 0.5695 - val_loss: 2122459520.0000 - val_mae: 27168.9258 - val_r2_score: 0.4274 - learning_rate: 0.0250\n",
      "Epoch 36/150\n",
      "\u001b[1m261/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1543814912.0000 - mae: 26156.6973 - r2_score: 0.5852\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1547234048.0000 - mae: 26182.1602 - r2_score: 0.5842 - val_loss: 2061277696.0000 - val_mae: 27099.7539 - val_r2_score: 0.4439 - learning_rate: 0.0250\n",
      "Epoch 37/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1533826816.0000 - mae: 25771.9492 - r2_score: 0.5787 - val_loss: 2056868096.0000 - val_mae: 26959.0977 - val_r2_score: 0.4451 - learning_rate: 0.0125\n",
      "Epoch 38/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1523838464.0000 - mae: 26015.5488 - r2_score: 0.5971 - val_loss: 2067045760.0000 - val_mae: 26846.6328 - val_r2_score: 0.4423 - learning_rate: 0.0125\n",
      "Epoch 39/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1437498880.0000 - mae: 25524.3652 - r2_score: 0.6062 - val_loss: 2070581120.0000 - val_mae: 27653.0254 - val_r2_score: 0.4414 - learning_rate: 0.0125\n",
      "Epoch 40/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1453156352.0000 - mae: 25457.1211 - r2_score: 0.6108 - val_loss: 2014393984.0000 - val_mae: 26727.3398 - val_r2_score: 0.4565 - learning_rate: 0.0125\n",
      "Epoch 41/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1423656064.0000 - mae: 25127.6133 - r2_score: 0.6225 - val_loss: 2087745792.0000 - val_mae: 26749.4199 - val_r2_score: 0.4368 - learning_rate: 0.0125\n",
      "Epoch 42/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1502400640.0000 - mae: 25380.6602 - r2_score: 0.6087 - val_loss: 2109003776.0000 - val_mae: 26866.5156 - val_r2_score: 0.4310 - learning_rate: 0.0125\n",
      "Epoch 43/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1460657664.0000 - mae: 25382.6113 - r2_score: 0.6144 - val_loss: 2082382464.0000 - val_mae: 26901.7832 - val_r2_score: 0.4382 - learning_rate: 0.0125\n",
      "Epoch 44/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1339014912.0000 - mae: 24727.3828 - r2_score: 0.6298 - val_loss: 2112143872.0000 - val_mae: 27051.1895 - val_r2_score: 0.4302 - learning_rate: 0.0125\n",
      "Epoch 45/150\n",
      "\u001b[1m260/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1450126976.0000 - mae: 25402.3691 - r2_score: 0.6090\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1451133440.0000 - mae: 25409.3574 - r2_score: 0.6090 - val_loss: 2082859904.0000 - val_mae: 26651.6387 - val_r2_score: 0.4381 - learning_rate: 0.0125\n",
      "Epoch 46/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1449488128.0000 - mae: 25563.5156 - r2_score: 0.6163 - val_loss: 2122713984.0000 - val_mae: 26798.5195 - val_r2_score: 0.4273 - learning_rate: 0.0063\n",
      "Epoch 47/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1434586496.0000 - mae: 24937.1992 - r2_score: 0.6167 - val_loss: 2102001536.0000 - val_mae: 26962.1309 - val_r2_score: 0.4329 - learning_rate: 0.0063\n",
      "Epoch 48/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1364354304.0000 - mae: 24772.0957 - r2_score: 0.6376 - val_loss: 2083003776.0000 - val_mae: 27013.8379 - val_r2_score: 0.4380 - learning_rate: 0.0063\n",
      "Epoch 49/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1361732352.0000 - mae: 24866.2520 - r2_score: 0.6264 - val_loss: 2070079616.0000 - val_mae: 27239.9121 - val_r2_score: 0.4415 - learning_rate: 0.0063\n",
      "Epoch 50/150\n",
      "\u001b[1m268/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1377134464.0000 - mae: 24866.6484 - r2_score: 0.6265\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1378104832.0000 - mae: 24867.5469 - r2_score: 0.6266 - val_loss: 2058405504.0000 - val_mae: 26920.9766 - val_r2_score: 0.4447 - learning_rate: 0.0063\n",
      "Epoch 50: early stopping\n",
      "Restoring model weights from the end of the best epoch: 40.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12800073728.0000 - mae: 95278.8438 - r2_score: -2.3586 - val_loss: 8525579776.0000 - val_mae: 78732.2344 - val_r2_score: -1.1862 - learning_rate: 0.0500\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8266373120.0000 - mae: 75317.6484 - r2_score: -1.3026 - val_loss: 5560012800.0000 - val_mae: 57714.6133 - val_r2_score: -0.4258 - learning_rate: 0.0500\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4092608000.0000 - mae: 47148.1289 - r2_score: -0.0875 - val_loss: 3852998912.0000 - val_mae: 40919.9570 - val_r2_score: 0.0120 - learning_rate: 0.0500\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2822580480.0000 - mae: 33160.1875 - r2_score: 0.2904 - val_loss: 3586510848.0000 - val_mae: 32335.2109 - val_r2_score: 0.0803 - learning_rate: 0.0500\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2314676992.0000 - mae: 29288.9570 - r2_score: 0.3856 - val_loss: 3699522816.0000 - val_mae: 29222.3438 - val_r2_score: 0.0513 - learning_rate: 0.0500\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2320562432.0000 - mae: 28970.8926 - r2_score: 0.4043 - val_loss: 3413664512.0000 - val_mae: 29006.2246 - val_r2_score: 0.1246 - learning_rate: 0.0500\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2377373440.0000 - mae: 28846.8184 - r2_score: 0.4061 - val_loss: 3737634048.0000 - val_mae: 28921.1133 - val_r2_score: 0.0416 - learning_rate: 0.0500\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2224343296.0000 - mae: 28450.0684 - r2_score: 0.4239 - val_loss: 3542057216.0000 - val_mae: 28958.0684 - val_r2_score: 0.0917 - learning_rate: 0.0500\n",
      "Epoch 9/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1973715200.0000 - mae: 27842.1855 - r2_score: 0.4399 - val_loss: 3288482560.0000 - val_mae: 29411.9199 - val_r2_score: 0.1567 - learning_rate: 0.0500\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2165270784.0000 - mae: 28558.7266 - r2_score: 0.4371 - val_loss: 2954743808.0000 - val_mae: 28558.6016 - val_r2_score: 0.2423 - learning_rate: 0.0500\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2122583936.0000 - mae: 28517.5312 - r2_score: 0.4383 - val_loss: 3022483200.0000 - val_mae: 29037.2598 - val_r2_score: 0.2249 - learning_rate: 0.0500\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2074111104.0000 - mae: 28129.4082 - r2_score: 0.4550 - val_loss: 2692939264.0000 - val_mae: 28400.3535 - val_r2_score: 0.3095 - learning_rate: 0.0500\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2108969088.0000 - mae: 28320.2988 - r2_score: 0.4364 - val_loss: 2650250240.0000 - val_mae: 28388.6699 - val_r2_score: 0.3204 - learning_rate: 0.0500\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2099385344.0000 - mae: 28408.6426 - r2_score: 0.4523 - val_loss: 2474253056.0000 - val_mae: 28028.3496 - val_r2_score: 0.3655 - learning_rate: 0.0500\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2019255040.0000 - mae: 27768.8340 - r2_score: 0.4709 - val_loss: 2328408832.0000 - val_mae: 27982.4199 - val_r2_score: 0.4029 - learning_rate: 0.0500\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1861324800.0000 - mae: 27455.2383 - r2_score: 0.4853 - val_loss: 2208755200.0000 - val_mae: 27626.9180 - val_r2_score: 0.4336 - learning_rate: 0.0500\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2071414912.0000 - mae: 27874.2715 - r2_score: 0.4579 - val_loss: 2346262272.0000 - val_mae: 28081.5312 - val_r2_score: 0.3983 - learning_rate: 0.0500\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2003926912.0000 - mae: 28048.0684 - r2_score: 0.4699 - val_loss: 2402595584.0000 - val_mae: 28138.8594 - val_r2_score: 0.3839 - learning_rate: 0.0500\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2040905472.0000 - mae: 28447.6074 - r2_score: 0.4784 - val_loss: 2244443136.0000 - val_mae: 27653.1758 - val_r2_score: 0.4245 - learning_rate: 0.0500\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1902549760.0000 - mae: 27429.7676 - r2_score: 0.4892 - val_loss: 2264696320.0000 - val_mae: 27504.8047 - val_r2_score: 0.4193 - learning_rate: 0.0500\n",
      "Epoch 21/150\n",
      "\u001b[1m261/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1982467584.0000 - mae: 27763.6465 - r2_score: 0.4789\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1985407360.0000 - mae: 27788.4766 - r2_score: 0.4785 - val_loss: 2248956928.0000 - val_mae: 28083.9375 - val_r2_score: 0.4233 - learning_rate: 0.0500\n",
      "Epoch 22/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1993490944.0000 - mae: 27677.5176 - r2_score: 0.5000 - val_loss: 2211069952.0000 - val_mae: 27221.1465 - val_r2_score: 0.4330 - learning_rate: 0.0250\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1802368128.0000 - mae: 26784.6504 - r2_score: 0.5278 - val_loss: 2193284096.0000 - val_mae: 27772.8926 - val_r2_score: 0.4376 - learning_rate: 0.0250\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1775100672.0000 - mae: 26839.7227 - r2_score: 0.5256 - val_loss: 2217677056.0000 - val_mae: 27285.9648 - val_r2_score: 0.4313 - learning_rate: 0.0250\n",
      "Epoch 25/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1837709696.0000 - mae: 27137.1953 - r2_score: 0.5254 - val_loss: 2289432576.0000 - val_mae: 27469.5312 - val_r2_score: 0.4129 - learning_rate: 0.0250\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1906104704.0000 - mae: 27179.1543 - r2_score: 0.5236 - val_loss: 2206282752.0000 - val_mae: 27773.2617 - val_r2_score: 0.4342 - learning_rate: 0.0250\n",
      "Epoch 27/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1713078272.0000 - mae: 26710.8750 - r2_score: 0.5365 - val_loss: 2345537024.0000 - val_mae: 28401.4824 - val_r2_score: 0.3985 - learning_rate: 0.0250\n",
      "Epoch 28/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1652461440.0000 - mae: 26616.2754 - r2_score: 0.5581\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1652853888.0000 - mae: 26617.4453 - r2_score: 0.5580 - val_loss: 2228670208.0000 - val_mae: 27700.2402 - val_r2_score: 0.4285 - learning_rate: 0.0250\n",
      "Epoch 29/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1600568704.0000 - mae: 26001.0586 - r2_score: 0.5644 - val_loss: 2231666688.0000 - val_mae: 27397.2773 - val_r2_score: 0.4277 - learning_rate: 0.0125\n",
      "Epoch 30/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1649287040.0000 - mae: 26152.6582 - r2_score: 0.5609 - val_loss: 2254013184.0000 - val_mae: 27901.6055 - val_r2_score: 0.4220 - learning_rate: 0.0125\n",
      "Epoch 31/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1585089792.0000 - mae: 25781.2754 - r2_score: 0.5783 - val_loss: 2221633280.0000 - val_mae: 27729.7578 - val_r2_score: 0.4303 - learning_rate: 0.0125\n",
      "Epoch 32/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1721911168.0000 - mae: 26675.4609 - r2_score: 0.5664 - val_loss: 2256127744.0000 - val_mae: 27352.3340 - val_r2_score: 0.4215 - learning_rate: 0.0125\n",
      "Epoch 33/150\n",
      "\u001b[1m264/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1652934784.0000 - mae: 26040.1660 - r2_score: 0.5636\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1654504832.0000 - mae: 26052.9102 - r2_score: 0.5635 - val_loss: 2257039616.0000 - val_mae: 27529.5938 - val_r2_score: 0.4212 - learning_rate: 0.0125\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 13069490176.0000 - mae: 96156.7656 - r2_score: -2.3616 - val_loss: 8833531904.0000 - val_mae: 81112.2109 - val_r2_score: -1.2752 - learning_rate: 0.0500\n",
      "Epoch 2/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 8557215232.0000 - mae: 76534.6562 - r2_score: -1.3088 - val_loss: 7155257344.0000 - val_mae: 68393.9219 - val_r2_score: -0.8429 - learning_rate: 0.0500\n",
      "Epoch 3/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 4278335232.0000 - mae: 48899.5273 - r2_score: -0.1411 - val_loss: 3205144576.0000 - val_mae: 36543.8008 - val_r2_score: 0.1745 - learning_rate: 0.0500\n",
      "Epoch 4/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2736473856.0000 - mae: 32752.8613 - r2_score: 0.2861 - val_loss: 2853359872.0000 - val_mae: 29175.8438 - val_r2_score: 0.2651 - learning_rate: 0.0500\n",
      "Epoch 5/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2288547072.0000 - mae: 29430.8418 - r2_score: 0.3777 - val_loss: 3172559872.0000 - val_mae: 28394.9590 - val_r2_score: 0.1829 - learning_rate: 0.0500\n",
      "Epoch 6/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2150589184.0000 - mae: 28760.5156 - r2_score: 0.4135 - val_loss: 3875235584.0000 - val_mae: 29099.9883 - val_r2_score: 0.0019 - learning_rate: 0.0500\n",
      "Epoch 7/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2292932096.0000 - mae: 29162.1113 - r2_score: 0.4097 - val_loss: 3095066624.0000 - val_mae: 28407.7246 - val_r2_score: 0.2028 - learning_rate: 0.0500\n",
      "Epoch 8/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2089141120.0000 - mae: 28796.5078 - r2_score: 0.4263 - val_loss: 3246005760.0000 - val_mae: 28843.0742 - val_r2_score: 0.1639 - learning_rate: 0.0500\n",
      "Epoch 9/150\n",
      "\u001b[1m274/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2062084736.0000 - mae: 28583.2832 - r2_score: 0.4344\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2065458304.0000 - mae: 28594.9941 - r2_score: 0.4341 - val_loss: 3629579008.0000 - val_mae: 29696.4922 - val_r2_score: 0.0651 - learning_rate: 0.0500\n",
      "Epoch 10/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2251713024.0000 - mae: 28916.5098 - r2_score: 0.4335 - val_loss: 3368889600.0000 - val_mae: 28279.9453 - val_r2_score: 0.1323 - learning_rate: 0.0250\n",
      "Epoch 11/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2119299840.0000 - mae: 28301.4336 - r2_score: 0.4537 - val_loss: 3095250176.0000 - val_mae: 28465.9824 - val_r2_score: 0.2028 - learning_rate: 0.0250\n",
      "Epoch 12/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1926887424.0000 - mae: 27769.5371 - r2_score: 0.4665 - val_loss: 2841224192.0000 - val_mae: 28202.7930 - val_r2_score: 0.2682 - learning_rate: 0.0250\n",
      "Epoch 13/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2024129408.0000 - mae: 27997.6523 - r2_score: 0.4676 - val_loss: 2608683264.0000 - val_mae: 27788.3613 - val_r2_score: 0.3281 - learning_rate: 0.0250\n",
      "Epoch 14/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1958311936.0000 - mae: 27798.1406 - r2_score: 0.4742 - val_loss: 2263577600.0000 - val_mae: 27649.5117 - val_r2_score: 0.4170 - learning_rate: 0.0250\n",
      "Epoch 15/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2124242176.0000 - mae: 28448.6465 - r2_score: 0.4542 - val_loss: 2347632384.0000 - val_mae: 28134.7070 - val_r2_score: 0.3953 - learning_rate: 0.0250\n",
      "Epoch 16/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1949103616.0000 - mae: 27861.2246 - r2_score: 0.4761 - val_loss: 2210051840.0000 - val_mae: 27488.7480 - val_r2_score: 0.4308 - learning_rate: 0.0250\n",
      "Epoch 17/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1790332928.0000 - mae: 27142.1230 - r2_score: 0.5076 - val_loss: 2221762816.0000 - val_mae: 27582.7695 - val_r2_score: 0.4278 - learning_rate: 0.0250\n",
      "Epoch 18/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1979118464.0000 - mae: 27635.2559 - r2_score: 0.4966 - val_loss: 2269280256.0000 - val_mae: 27668.4141 - val_r2_score: 0.4155 - learning_rate: 0.0250\n",
      "Epoch 19/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1884624000.0000 - mae: 27364.5762 - r2_score: 0.5032 - val_loss: 2234211072.0000 - val_mae: 27771.6172 - val_r2_score: 0.4245 - learning_rate: 0.0250\n",
      "Epoch 20/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1950627456.0000 - mae: 27775.5352 - r2_score: 0.4972 - val_loss: 2186262272.0000 - val_mae: 27358.1738 - val_r2_score: 0.4369 - learning_rate: 0.0250\n",
      "Epoch 21/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1798770560.0000 - mae: 27357.4609 - r2_score: 0.5143 - val_loss: 2302778368.0000 - val_mae: 27882.3027 - val_r2_score: 0.4069 - learning_rate: 0.0250\n",
      "Epoch 22/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1915870720.0000 - mae: 27724.2598 - r2_score: 0.5172 - val_loss: 2250137600.0000 - val_mae: 27538.9883 - val_r2_score: 0.4204 - learning_rate: 0.0250\n",
      "Epoch 23/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1858165120.0000 - mae: 27344.8047 - r2_score: 0.5319 - val_loss: 2183030784.0000 - val_mae: 28461.4727 - val_r2_score: 0.4377 - learning_rate: 0.0250\n",
      "Epoch 24/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1707507328.0000 - mae: 26915.8047 - r2_score: 0.5272 - val_loss: 2235017984.0000 - val_mae: 27598.3105 - val_r2_score: 0.4243 - learning_rate: 0.0250\n",
      "Epoch 25/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1798593024.0000 - mae: 27247.0391 - r2_score: 0.5247 - val_loss: 2209681920.0000 - val_mae: 28474.0059 - val_r2_score: 0.4309 - learning_rate: 0.0250\n",
      "Epoch 26/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1758294656.0000 - mae: 27079.5332 - r2_score: 0.5349 - val_loss: 2199318016.0000 - val_mae: 27642.9922 - val_r2_score: 0.4335 - learning_rate: 0.0250\n",
      "Epoch 27/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1709182208.0000 - mae: 27045.5000 - r2_score: 0.5421 - val_loss: 2199977728.0000 - val_mae: 27729.0977 - val_r2_score: 0.4334 - learning_rate: 0.0250\n",
      "Epoch 28/150\n",
      "\u001b[1m260/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1771664512.0000 - mae: 27167.6719 - r2_score: 0.5463\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1770952576.0000 - mae: 27168.9863 - r2_score: 0.5455 - val_loss: 2268012288.0000 - val_mae: 28174.4121 - val_r2_score: 0.4158 - learning_rate: 0.0250\n",
      "Epoch 29/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1615123200.0000 - mae: 26826.8457 - r2_score: 0.5687 - val_loss: 2191571968.0000 - val_mae: 27461.4453 - val_r2_score: 0.4355 - learning_rate: 0.0125\n",
      "Epoch 30/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1539554304.0000 - mae: 26173.7363 - r2_score: 0.5694 - val_loss: 2139764736.0000 - val_mae: 27266.9219 - val_r2_score: 0.4489 - learning_rate: 0.0125\n",
      "Epoch 31/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1654943232.0000 - mae: 26934.4746 - r2_score: 0.5744 - val_loss: 2195064320.0000 - val_mae: 27630.2500 - val_r2_score: 0.4346 - learning_rate: 0.0125\n",
      "Epoch 32/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1629830784.0000 - mae: 26367.1172 - r2_score: 0.5813 - val_loss: 2181881856.0000 - val_mae: 27371.0176 - val_r2_score: 0.4380 - learning_rate: 0.0125\n",
      "Epoch 33/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1577684608.0000 - mae: 26213.2227 - r2_score: 0.5894 - val_loss: 2193652480.0000 - val_mae: 27666.4160 - val_r2_score: 0.4350 - learning_rate: 0.0125\n",
      "Epoch 34/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1655954688.0000 - mae: 26191.2305 - r2_score: 0.5831 - val_loss: 2238509312.0000 - val_mae: 27451.9141 - val_r2_score: 0.4234 - learning_rate: 0.0125\n",
      "Epoch 35/150\n",
      "\u001b[1m267/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1666068736.0000 - mae: 26445.5488 - r2_score: 0.5844\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1662772608.0000 - mae: 26434.1953 - r2_score: 0.5843 - val_loss: 2182067456.0000 - val_mae: 27553.3477 - val_r2_score: 0.4380 - learning_rate: 0.0125\n",
      "Epoch 36/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1510880384.0000 - mae: 25673.3203 - r2_score: 0.5924 - val_loss: 2214164736.0000 - val_mae: 27899.6543 - val_r2_score: 0.4297 - learning_rate: 0.0063\n",
      "Epoch 37/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1570585216.0000 - mae: 26095.1191 - r2_score: 0.5993 - val_loss: 2190287616.0000 - val_mae: 27373.5410 - val_r2_score: 0.4359 - learning_rate: 0.0063\n",
      "Epoch 38/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1576010496.0000 - mae: 26009.6719 - r2_score: 0.5977 - val_loss: 2198213376.0000 - val_mae: 27472.4492 - val_r2_score: 0.4338 - learning_rate: 0.0063\n",
      "Epoch 39/150\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1434838144.0000 - mae: 25538.2520 - r2_score: 0.6081 - val_loss: 2237943296.0000 - val_mae: 27637.0781 - val_r2_score: 0.4236 - learning_rate: 0.0063\n",
      "Epoch 40/150\n",
      "\u001b[1m269/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1570380544.0000 - mae: 25819.2305 - r2_score: 0.5954\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.\n",
      "\u001b[1m279/279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1566955008.0000 - mae: 25815.1465 - r2_score: 0.5960 - val_loss: 2192166656.0000 - val_mae: 27347.8105 - val_r2_score: 0.4354 - learning_rate: 0.0063\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n",
      "\u001b[1m88/88\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Epoch 1/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 12641866752.0000 - mae: 94438.2891 - r2_score: -2.2784 - val_loss: 7582025216.0000 - val_mae: 73552.3047 - val_r2_score: -1.0188 - learning_rate: 0.0500\n",
      "Epoch 2/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6920111616.0000 - mae: 66706.2500 - r2_score: -0.8400 - val_loss: 4011334656.0000 - val_mae: 46539.8750 - val_r2_score: -0.0681 - learning_rate: 0.0500\n",
      "Epoch 3/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3351430144.0000 - mae: 38509.7734 - r2_score: 0.1345 - val_loss: 2767305472.0000 - val_mae: 30935.1895 - val_r2_score: 0.2632 - learning_rate: 0.0500\n",
      "Epoch 4/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2437664000.0000 - mae: 30261.8945 - r2_score: 0.3576 - val_loss: 2520480256.0000 - val_mae: 28801.6719 - val_r2_score: 0.3289 - learning_rate: 0.0500\n",
      "Epoch 5/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2283576576.0000 - mae: 28986.5859 - r2_score: 0.4071 - val_loss: 2923802112.0000 - val_mae: 28693.2129 - val_r2_score: 0.2215 - learning_rate: 0.0500\n",
      "Epoch 6/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2195764224.0000 - mae: 28738.1699 - r2_score: 0.4126 - val_loss: 2814115584.0000 - val_mae: 28347.6191 - val_r2_score: 0.2507 - learning_rate: 0.0500\n",
      "Epoch 7/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2259431168.0000 - mae: 29300.1914 - r2_score: 0.4265 - val_loss: 3074854656.0000 - val_mae: 28496.8730 - val_r2_score: 0.1813 - learning_rate: 0.0500\n",
      "Epoch 8/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2314598400.0000 - mae: 29437.5059 - r2_score: 0.4152 - val_loss: 2629900544.0000 - val_mae: 28320.5273 - val_r2_score: 0.2998 - learning_rate: 0.0500\n",
      "Epoch 9/150\n",
      "\u001b[1m340/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2093135616.0000 - mae: 28459.7930 - r2_score: 0.4208\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2096620416.0000 - mae: 28474.6113 - r2_score: 0.4207 - val_loss: 2714996224.0000 - val_mae: 28130.3613 - val_r2_score: 0.2771 - learning_rate: 0.0500\n",
      "Epoch 10/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2138707712.0000 - mae: 28507.1758 - r2_score: 0.4325 - val_loss: 2543804416.0000 - val_mae: 27891.2656 - val_r2_score: 0.3227 - learning_rate: 0.0250\n",
      "Epoch 11/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1975156992.0000 - mae: 27961.8496 - r2_score: 0.4551 - val_loss: 2600684544.0000 - val_mae: 27770.9023 - val_r2_score: 0.3075 - learning_rate: 0.0250\n",
      "Epoch 12/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2177135616.0000 - mae: 28521.9004 - r2_score: 0.4556 - val_loss: 2248405760.0000 - val_mae: 27514.8926 - val_r2_score: 0.4013 - learning_rate: 0.0250\n",
      "Epoch 13/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2113138432.0000 - mae: 28467.1348 - r2_score: 0.4515 - val_loss: 2213231872.0000 - val_mae: 27186.1348 - val_r2_score: 0.4107 - learning_rate: 0.0250\n",
      "Epoch 14/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1970242816.0000 - mae: 27800.1641 - r2_score: 0.4681 - val_loss: 2115873536.0000 - val_mae: 26918.2910 - val_r2_score: 0.4366 - learning_rate: 0.0250\n",
      "Epoch 15/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1962028672.0000 - mae: 27930.8379 - r2_score: 0.4703 - val_loss: 2090226304.0000 - val_mae: 27178.6230 - val_r2_score: 0.4435 - learning_rate: 0.0250\n",
      "Epoch 16/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1938194048.0000 - mae: 27505.1621 - r2_score: 0.4837 - val_loss: 2105154944.0000 - val_mae: 27210.3398 - val_r2_score: 0.4395 - learning_rate: 0.0250\n",
      "Epoch 17/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1971534208.0000 - mae: 28028.4844 - r2_score: 0.4774 - val_loss: 2131678464.0000 - val_mae: 27350.3887 - val_r2_score: 0.4324 - learning_rate: 0.0250\n",
      "Epoch 18/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1866663168.0000 - mae: 27261.6699 - r2_score: 0.4954 - val_loss: 2078227968.0000 - val_mae: 27360.3320 - val_r2_score: 0.4466 - learning_rate: 0.0250\n",
      "Epoch 19/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1939259008.0000 - mae: 27825.8105 - r2_score: 0.4923 - val_loss: 2041588352.0000 - val_mae: 27061.3125 - val_r2_score: 0.4564 - learning_rate: 0.0250\n",
      "Epoch 20/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1911056512.0000 - mae: 27673.8379 - r2_score: 0.4897 - val_loss: 2176354816.0000 - val_mae: 27583.1797 - val_r2_score: 0.4205 - learning_rate: 0.0250\n",
      "Epoch 21/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1841013760.0000 - mae: 27285.0996 - r2_score: 0.5086 - val_loss: 2080472704.0000 - val_mae: 27256.9277 - val_r2_score: 0.4461 - learning_rate: 0.0250\n",
      "Epoch 22/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1914002176.0000 - mae: 27776.6367 - r2_score: 0.5023 - val_loss: 2063212928.0000 - val_mae: 27279.8223 - val_r2_score: 0.4506 - learning_rate: 0.0250\n",
      "Epoch 23/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1798598016.0000 - mae: 27240.3301 - r2_score: 0.5072 - val_loss: 2088205184.0000 - val_mae: 27309.1602 - val_r2_score: 0.4440 - learning_rate: 0.0250\n",
      "Epoch 24/150\n",
      "\u001b[1m347/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1901489536.0000 - mae: 27580.5996 - r2_score: 0.5091\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1901479296.0000 - mae: 27579.5625 - r2_score: 0.5090 - val_loss: 2098699520.0000 - val_mae: 27366.6152 - val_r2_score: 0.4412 - learning_rate: 0.0250\n",
      "Epoch 25/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1917921536.0000 - mae: 27629.6914 - r2_score: 0.5106 - val_loss: 2084352512.0000 - val_mae: 26673.0996 - val_r2_score: 0.4450 - learning_rate: 0.0125\n",
      "Epoch 26/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1775129472.0000 - mae: 26753.8262 - r2_score: 0.5438 - val_loss: 2090080512.0000 - val_mae: 26964.3438 - val_r2_score: 0.4435 - learning_rate: 0.0125\n",
      "Epoch 27/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1740636160.0000 - mae: 26805.3477 - r2_score: 0.5410 - val_loss: 2092267648.0000 - val_mae: 26962.5898 - val_r2_score: 0.4429 - learning_rate: 0.0125\n",
      "Epoch 28/150\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1686159232.0000 - mae: 26426.7324 - r2_score: 0.5418 - val_loss: 2116012032.0000 - val_mae: 26869.8555 - val_r2_score: 0.4366 - learning_rate: 0.0125\n",
      "Epoch 29/150\n",
      "\u001b[1m348/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1721210496.0000 - mae: 26773.7227 - r2_score: 0.5479\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1721252480.0000 - mae: 26773.4707 - r2_score: 0.5479 - val_loss: 2110684544.0000 - val_mae: 27384.6504 - val_r2_score: 0.4380 - learning_rate: 0.0125\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    clone(preprocessor), \n",
    "    GridSearchCV(\n",
    "        estimator=KerasRegressor(\n",
    "            model=build_model,\n",
    "            epochs=150,\n",
    "            batch_size=64,\n",
    "            verbose=1,\n",
    "            validation_split=0.2,\n",
    "            callbacks=[\n",
    "                EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "                ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-6, verbose=1)\n",
    "            ]\n",
    "        ),\n",
    "        param_grid={\n",
    "            'model__learning_rate': [1e-2, 5e-2]\n",
    "        },\n",
    "        scoring=\"r2\",\n",
    "        cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        verbose=1,\n",
    "    )\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff61d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__learning_rate': 0.05}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = model[-1]\n",
    "best_params = search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea244a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m436/436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step\n",
      "Train R2: 0.5695\n",
      "Train RMSE: 40360.7444\n",
      "Train MAE: 24419.8215\n"
     ]
    }
   ],
   "source": [
    "result_train = salary.evaluate_train_predictions(model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6182d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step\n",
      "Test R2: 0.5106\n",
      "Test RMSE: 40784.4440\n",
      "Test MAE: 26181.9552\n"
     ]
    }
   ],
   "source": [
    "result_test = salary.evaluate_test_predictions(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20e4e92",
   "metadata": {},
   "source": [
    "## Train & Evaluate Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a197b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 12704825344.0000 - mae: 94878.9766 - r2_score: -2.3119 - val_loss: 7874866176.0000 - val_mae: 75407.8203 - val_r2_score: -1.0968 - learning_rate: 0.0500\n",
      "Epoch 2/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7290342400.0000 - mae: 67988.2969 - r2_score: -0.8460 - val_loss: 4445874176.0000 - val_mae: 50241.9102 - val_r2_score: -0.1838 - learning_rate: 0.0500\n",
      "Epoch 3/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3078017792.0000 - mae: 37809.7812 - r2_score: 0.1505 - val_loss: 2789701120.0000 - val_mae: 31797.0801 - val_r2_score: 0.2572 - learning_rate: 0.0500\n",
      "Epoch 4/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2689631488.0000 - mae: 30840.7285 - r2_score: 0.3514 - val_loss: 2533696000.0000 - val_mae: 28245.9941 - val_r2_score: 0.3254 - learning_rate: 0.0500\n",
      "Epoch 5/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2217360640.0000 - mae: 28843.8770 - r2_score: 0.4061 - val_loss: 2757332480.0000 - val_mae: 28072.6289 - val_r2_score: 0.2658 - learning_rate: 0.0500\n",
      "Epoch 6/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2222894336.0000 - mae: 29364.6973 - r2_score: 0.4117 - val_loss: 2614228736.0000 - val_mae: 28160.1035 - val_r2_score: 0.3039 - learning_rate: 0.0500\n",
      "Epoch 7/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2353823232.0000 - mae: 29695.1621 - r2_score: 0.4051 - val_loss: 2762497536.0000 - val_mae: 28135.8008 - val_r2_score: 0.2645 - learning_rate: 0.0500\n",
      "Epoch 8/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2102834176.0000 - mae: 28674.7871 - r2_score: 0.4342 - val_loss: 2590509312.0000 - val_mae: 28291.8965 - val_r2_score: 0.3102 - learning_rate: 0.0500\n",
      "Epoch 9/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2038410624.0000 - mae: 28496.9746 - r2_score: 0.4364 - val_loss: 2254513152.0000 - val_mae: 28190.8496 - val_r2_score: 0.3997 - learning_rate: 0.0500\n",
      "Epoch 10/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2142054400.0000 - mae: 28856.0586 - r2_score: 0.4308 - val_loss: 2551566080.0000 - val_mae: 27875.8555 - val_r2_score: 0.3206 - learning_rate: 0.0500\n",
      "Epoch 11/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1979753728.0000 - mae: 28231.1230 - r2_score: 0.4563 - val_loss: 2336588800.0000 - val_mae: 28201.0000 - val_r2_score: 0.3779 - learning_rate: 0.0500\n",
      "Epoch 12/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2376537600.0000 - mae: 29163.7305 - r2_score: 0.4113 - val_loss: 2119073152.0000 - val_mae: 27710.2441 - val_r2_score: 0.4358 - learning_rate: 0.0500\n",
      "Epoch 13/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2145673984.0000 - mae: 29051.9102 - r2_score: 0.4368 - val_loss: 2518709248.0000 - val_mae: 28420.6270 - val_r2_score: 0.3294 - learning_rate: 0.0500\n",
      "Epoch 14/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2054488960.0000 - mae: 28551.4082 - r2_score: 0.4471 - val_loss: 2150259456.0000 - val_mae: 27409.7188 - val_r2_score: 0.4275 - learning_rate: 0.0500\n",
      "Epoch 15/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2044780800.0000 - mae: 28450.1113 - r2_score: 0.4557 - val_loss: 2191822592.0000 - val_mae: 27438.5664 - val_r2_score: 0.4164 - learning_rate: 0.0500\n",
      "Epoch 16/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2028929152.0000 - mae: 28289.2676 - r2_score: 0.4467 - val_loss: 2105844608.0000 - val_mae: 27103.3926 - val_r2_score: 0.4393 - learning_rate: 0.0500\n",
      "Epoch 17/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1993504896.0000 - mae: 28194.3027 - r2_score: 0.4628 - val_loss: 2125793536.0000 - val_mae: 27393.8008 - val_r2_score: 0.4340 - learning_rate: 0.0500\n",
      "Epoch 18/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2219676416.0000 - mae: 28782.8203 - r2_score: 0.4537 - val_loss: 2093182592.0000 - val_mae: 27113.2148 - val_r2_score: 0.4427 - learning_rate: 0.0500\n",
      "Epoch 19/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1975166080.0000 - mae: 28063.7852 - r2_score: 0.4654 - val_loss: 2129292032.0000 - val_mae: 27414.3008 - val_r2_score: 0.4331 - learning_rate: 0.0500\n",
      "Epoch 20/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2178376448.0000 - mae: 28687.5957 - r2_score: 0.4579 - val_loss: 2109842432.0000 - val_mae: 27121.7305 - val_r2_score: 0.4382 - learning_rate: 0.0500\n",
      "Epoch 21/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1906037376.0000 - mae: 27894.4277 - r2_score: 0.4872 - val_loss: 2083712512.0000 - val_mae: 27728.2988 - val_r2_score: 0.4452 - learning_rate: 0.0500\n",
      "Epoch 22/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2035856000.0000 - mae: 28191.1914 - r2_score: 0.4659 - val_loss: 2096110336.0000 - val_mae: 27704.4609 - val_r2_score: 0.4419 - learning_rate: 0.0500\n",
      "Epoch 23/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1966455040.0000 - mae: 27938.2148 - r2_score: 0.4800 - val_loss: 2112746368.0000 - val_mae: 27507.9473 - val_r2_score: 0.4375 - learning_rate: 0.0500\n",
      "Epoch 24/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1942092544.0000 - mae: 27738.5391 - r2_score: 0.4791 - val_loss: 2177803008.0000 - val_mae: 27640.9473 - val_r2_score: 0.4201 - learning_rate: 0.0500\n",
      "Epoch 25/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1989755776.0000 - mae: 28324.7441 - r2_score: 0.4723 - val_loss: 2094617472.0000 - val_mae: 27339.1309 - val_r2_score: 0.4423 - learning_rate: 0.0500\n",
      "Epoch 26/100\n",
      "\u001b[1m345/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2069106560.0000 - mae: 28287.8672 - r2_score: 0.4787\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2067856000.0000 - mae: 28287.5137 - r2_score: 0.4787 - val_loss: 2130405248.0000 - val_mae: 27713.8926 - val_r2_score: 0.4328 - learning_rate: 0.0500\n",
      "Epoch 27/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2040416768.0000 - mae: 28112.2812 - r2_score: 0.4916 - val_loss: 2037912064.0000 - val_mae: 27206.6211 - val_r2_score: 0.4574 - learning_rate: 0.0250\n",
      "Epoch 28/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1857775360.0000 - mae: 27228.2051 - r2_score: 0.5102 - val_loss: 2165955072.0000 - val_mae: 27949.3867 - val_r2_score: 0.4233 - learning_rate: 0.0250\n",
      "Epoch 29/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1798487424.0000 - mae: 27436.9551 - r2_score: 0.5197 - val_loss: 2098170112.0000 - val_mae: 27666.6055 - val_r2_score: 0.4413 - learning_rate: 0.0250\n",
      "Epoch 30/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1684762752.0000 - mae: 26997.8457 - r2_score: 0.5318 - val_loss: 2087179008.0000 - val_mae: 27506.4961 - val_r2_score: 0.4443 - learning_rate: 0.0250\n",
      "Epoch 31/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1682297856.0000 - mae: 26586.4180 - r2_score: 0.5406 - val_loss: 2082381696.0000 - val_mae: 27092.2266 - val_r2_score: 0.4455 - learning_rate: 0.0250\n",
      "Epoch 32/100\n",
      "\u001b[1m336/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1760439936.0000 - mae: 27091.6914 - r2_score: 0.5384\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1762224768.0000 - mae: 27101.3984 - r2_score: 0.5379 - val_loss: 2120221824.0000 - val_mae: 27314.0918 - val_r2_score: 0.4355 - learning_rate: 0.0250\n",
      "Epoch 33/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1708584448.0000 - mae: 26780.9355 - r2_score: 0.5383 - val_loss: 2086891648.0000 - val_mae: 27307.5762 - val_r2_score: 0.4443 - learning_rate: 0.0125\n",
      "Epoch 34/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1740036608.0000 - mae: 26690.8105 - r2_score: 0.5486 - val_loss: 2093526272.0000 - val_mae: 27356.6348 - val_r2_score: 0.4426 - learning_rate: 0.0125\n",
      "Epoch 35/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1573028992.0000 - mae: 26435.3906 - r2_score: 0.5768 - val_loss: 2151783680.0000 - val_mae: 27400.9043 - val_r2_score: 0.4271 - learning_rate: 0.0125\n",
      "Epoch 36/100\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1589123456.0000 - mae: 26338.3047 - r2_score: 0.5604 - val_loss: 2078214656.0000 - val_mae: 27449.2402 - val_r2_score: 0.4467 - learning_rate: 0.0125\n",
      "Epoch 37/100\n",
      "\u001b[1m337/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1526743040.0000 - mae: 26297.3457 - r2_score: 0.5820\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.\n",
      "\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 1531650304.0000 - mae: 26306.5703 - r2_score: 0.5813 - val_loss: 2084434304.0000 - val_mae: 27292.2422 - val_r2_score: 0.4450 - learning_rate: 0.0125\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n"
     ]
    }
   ],
   "source": [
    "best_model = make_pipeline(\n",
    "    clone(preprocessor),\n",
    "    KerasRegressor(\n",
    "        model=build_model,\n",
    "        epochs=150,\n",
    "        batch_size=64,\n",
    "        verbose=1,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[\n",
    "            EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "            ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-6, verbose=1)\n",
    "        ],\n",
    "        **best_params\n",
    "    )\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cb75a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m436/436\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Train R2: 0.5881\n",
      "Train RMSE: 39481.3863\n",
      "Train MAE: 24281.0941\n",
      "\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step\n",
      "Test R2: 0.5072\n",
      "Test RMSE: 40926.0630\n",
      "Test MAE: 26105.7880\n"
     ]
    }
   ],
   "source": [
    "results_train = salary.evaluate_train_predictions(best_model.predict(X_train))\n",
    "result_test = salary.evaluate_test_predictions(best_model.predict(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
