{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### laod in the extracted JDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"combined_row_0_to_34976_extracted_jd.json\", \"r\") as f:\n",
    "    data = json.load(f)  # Load JSON into a Python dictionary\n",
    "\n",
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Required_Skills</th>\n",
       "      <th>Educational_Requirements</th>\n",
       "      <th>Experience_Level</th>\n",
       "      <th>Preferred_Qualifications</th>\n",
       "      <th>Compensation_and_Benefits</th>\n",
       "      <th>job_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy, adherence to protocols, detail-orien...</td>\n",
       "      <td>Completed sophomore year in college with at le...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Majoring in Chemistry or Chemical Engineering....</td>\n",
       "      <td>$17.00/hr - $22.50/hr. Not eligible for benefits</td>\n",
       "      <td>3884812895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Required_Skills  \\\n",
       "0  Accuracy, adherence to protocols, detail-orien...   \n",
       "\n",
       "                            Educational_Requirements Experience_Level  \\\n",
       "0  Completed sophomore year in college with at le...              N/A   \n",
       "\n",
       "                            Preferred_Qualifications  \\\n",
       "0  Majoring in Chemistry or Chemical Engineering....   \n",
       "\n",
       "                          Compensation_and_Benefits      job_id  \n",
       "0  $17.00/hr - $22.50/hr. Not eligible for benefits  3884812895  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35604"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/jobs_clean_nt.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start to merge the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['job_id','description']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.set_index(\"job_id\", inplace=True)\n",
    "data_df.set_index(\"job_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>921716</th>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829192</th>\n",
       "      <td>At Aspen Therapy and Wellness , we are committ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               description\n",
       "job_id                                                    \n",
       "921716   Job descriptionA leading real estate firm in N...\n",
       "1829192  At Aspen Therapy and Wellness , we are committ..."
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['Required_Skills'] = 'N/A'\n",
    "new_df['Educational_Requirements'] = 'N/A'\n",
    "new_df['Experience_Level'] = 'N/A'\n",
    "new_df['Preferred_Qualifications'] = 'N/A'\n",
    "new_df['Compensation_and_Benefits'] = 'N/A'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.update(data_df)\n",
    "\n",
    "# Reset index to bring back 'job_id' as a column\n",
    "new_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35604"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop those columns with N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = new_df.drop(new_df[new_df.isin([\"N/A\"]).any(axis=1)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12120\n"
     ]
    }
   ],
   "source": [
    "len(df_cleaned)\n",
    "print(len(df_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly select 1,000 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = df_cleaned.sample(n=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>description</th>\n",
       "      <th>Required_Skills</th>\n",
       "      <th>Educational_Requirements</th>\n",
       "      <th>Experience_Level</th>\n",
       "      <th>Preferred_Qualifications</th>\n",
       "      <th>Compensation_and_Benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14776</th>\n",
       "      <td>3901387952</td>\n",
       "      <td>We are currently seeking a qualified candidate...</td>\n",
       "      <td>Office services/facility management, MS Office...</td>\n",
       "      <td>High School Diploma</td>\n",
       "      <td>5+ years</td>\n",
       "      <td>Prior leadership experience</td>\n",
       "      <td>Annual salary $55,000 to $64,000, benefits not...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           job_id                                        description  \\\n",
       "14776  3901387952  We are currently seeking a qualified candidate...   \n",
       "\n",
       "                                         Required_Skills  \\\n",
       "14776  Office services/facility management, MS Office...   \n",
       "\n",
       "      Educational_Requirements Experience_Level     Preferred_Qualifications  \\\n",
       "14776      High School Diploma         5+ years  Prior leadership experience   \n",
       "\n",
       "                               Compensation_and_Benefits  \n",
       "14776  Annual salary $55,000 to $64,000, benefits not...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the same batch process class as the one we used to extract the JDs, but now with gpt 4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "class MessageInfo(BaseModel):\n",
    "    Required_Skills: str\n",
    "    Educational_Requirements: str\n",
    "    Experience_Level: str\n",
    "    Preferred_Qualifications: str\n",
    "    Compensation_and_Benefits:str \n",
    "\n",
    "class Messages(BaseModel):\n",
    "    messages: List[MessageInfo]\n",
    "\n",
    "class BatchProcess():\n",
    "    def __init__(self, df:pd.DataFrame, start_index: int, batch_start_number:int, system_message:str):\n",
    "        \"\"\" \n",
    "        prepares raw jd from df, sends it to llms and writes outputs to json\n",
    "        \n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.start_index = start_index #index of the dataframe to START\n",
    "        self.batch_start_number = batch_start_number #batch number to START\n",
    "        self.system_message = system_message\n",
    "\n",
    "    def process(self, no_of_batches:int, batch_size:int) -> None:\n",
    "        #prepare the messages in the batch\n",
    "        for i in range(no_of_batches):\n",
    "            \n",
    "            messages, job_ids, checkpoint = self.prepare_llm_inputs(self.df, self.start_index, batch_size) #process before llm\n",
    "            #print(checkpoint) #debug\n",
    "            llm_structured_output = self.get_structured_output_from_llm(self.system_message, messages) #pass to llm, get responses\n",
    "\n",
    "\n",
    "            if len(llm_structured_output.messages) != len(job_ids):\n",
    "                print(messages)\n",
    "                print(\"job_ids:\",job_ids)\n",
    "                print(llm_structured_output.messages)\n",
    "                raise ValueError(f\"Error: Expected batch size of {batch_size}, but got jobids: {len(job_ids)} and llmoutputs: {len(llm_structured_output.messages)}.\")\n",
    "\n",
    "            batch_jds = self.append_jb_ids(job_ids, llm_structured_output) #process output, append jd ids to the response\n",
    "\n",
    "            self.write_to_file(batch_jds, checkpoint, self.batch_start_number) #write to json for the batch\n",
    "            \n",
    "            self.start_index = checkpoint\n",
    "\n",
    "            self.batch_start_number += 1\n",
    "        \n",
    "    # need to iterate through the rows in the df for that batch from the start checkpoint, \n",
    "    def prepare_llm_inputs(self, df: pd.DataFrame, checkpoint:int, batch_size:int) -> tuple[str, List[int], int]:\n",
    "        \"\"\" \n",
    "        This function iterates through the rows in the dataframe in that batch and prepares multiple raw JDs into one message/string for the llm\n",
    "        returns the updated checkpoint, input prompt which is a string and the list of their job ids for addition later\n",
    "        \"\"\"\n",
    "        messages =\"\"\n",
    "        job_ids = []\n",
    "        counter = 1\n",
    "        for i in range(checkpoint, checkpoint+batch_size):\n",
    "            job_id = int(df.iloc[i]['job_id'])\n",
    "            raw_jd = df.iloc[i]['description'].strip()\n",
    "            job_ids.append(job_id)\n",
    "            messages += f\"<Job {counter}>\\n{raw_jd}\\n</Job {counter}>\\n\\n\"\n",
    "            counter+=1\n",
    "        # Check if the number of job ids does not match the batch size\n",
    "        if len(job_ids) != batch_size:\n",
    "            \n",
    "            raise ValueError(f\"Error: Expected batch size of {batch_size}, but got {len(job_ids)}.\")\n",
    "\n",
    "        return (messages, job_ids, checkpoint + batch_size)\n",
    "    \n",
    "\n",
    "    # USING JSON STRUCTURED FORMAT\n",
    "    # def prepare_llm_inputs(self, df: pd.DataFrame, checkpoint:int, batch_size:int) -> tuple[str, List[int], int]:\n",
    "    #     \"\"\" \n",
    "    #     This function iterates through the rows in the dataframe in that batch and prepares multiple raw JDs into one message/string for the llm\n",
    "    #     returns the updated checkpoint, input prompt which is a string and the list of their job ids for addition later\n",
    "    #     \"\"\"\n",
    "    #     job_ids = []\n",
    "    #     counter = 1\n",
    "    #     job_list = []\n",
    "    #     for i in range(checkpoint, checkpoint+batch_size):\n",
    "    #         job_id = int(df.iloc[i]['job_id'])\n",
    "    #         raw_jd = df.iloc[i]['description'].strip()\n",
    "    #         job_ids.append(job_id)\n",
    "    #         job_list.append({\n",
    "    #             \"job\": counter, \n",
    "    #             \"raw description\": raw_jd\n",
    "    #         })\n",
    "    #         counter+=1\n",
    "    #     messages = json.dumps({\"jobs\": job_list}, indent=4)\n",
    "\n",
    "    #     return (messages, job_ids, checkpoint + batch_size)\n",
    "            \n",
    "    def get_structured_output_from_llm(self, system_message: str, user_message:str) -> Messages:\n",
    "        \"\"\" \n",
    "        sends the messages to gemini, returns a Messages object\n",
    "        \"\"\"\n",
    "        response = client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-mini-2024-07-18\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_message\n",
    "                }\n",
    "            ],\n",
    "            response_format=Messages,\n",
    "        )\n",
    "        return response.choices[0].message.parsed\n",
    "    \n",
    "    # we need to append the job ids to each message, saves output to json file\n",
    "    def append_jb_ids(self, job_ids:List, messages_list: Messages) -> List:\n",
    "        batch_jds = []\n",
    "        for idx, message in enumerate(messages_list.messages):\n",
    "            temp = message.model_dump()\n",
    "            #print(temp, idx)\n",
    "            temp['job_id'] = job_ids[idx]\n",
    "            batch_jds.append(temp)\n",
    "\n",
    "        return batch_jds\n",
    "    \n",
    "    def write_to_file(self, batch_jds:List, row_checkpoint, batch_no) -> None:\n",
    "            row_checkpoint -= 1\n",
    "            dir_name = \"extracted_jds\"\n",
    "            os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "            filename = f\"{dir_name}/batch_{batch_no}_row_{row_checkpoint}_extracted_jd.json\"\n",
    "\n",
    "            with open(filename, \"w\") as f:\n",
    "                json.dump(batch_jds, f, indent=4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = '''\n",
    "You are to summarize the following features concisely from each job description: \"Core Responsibilities, Required Skills, Educational Requirements, Experience Level, Preferred Qualifications, Compensation and Benefits.\n",
    "\n",
    "Please return the output in the following format:\n",
    "\n",
    "{\n",
    "  \"Core Responsibilities\": \"Summarize the core responsibilites of the job here\",\n",
    "  \"Required Skills\": \"Summarize the required skills here\",\n",
    "  \"Educational Requirements\": \"Summarize the educational requirements\",\n",
    "  \"Experience Level\": \"Summarize the experience level in years, if none put N/A\",\n",
    "  \"Preferred Qualifications\": \"Summarize the qualifications required\",\n",
    "  \"Compensation and Benefits\": \"Summarize the monthly or hourly salary, if none put N/A\"\n",
    "}\n",
    "return the output as a string, not markdown\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_process = BatchProcess(df=sampled_df, start_index=0, batch_start_number=1, system_message=system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mbatch_process\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mBatchProcess.process\u001b[39m\u001b[34m(self, no_of_batches, batch_size)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, no_of_batches:\u001b[38;5;28mint\u001b[39m, batch_size:\u001b[38;5;28mint\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m#prepare the messages in the batch\u001b[39;00m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(no_of_batches):\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         messages, job_ids, checkpoint = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprepare_llm_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#process before llm\u001b[39;00m\n\u001b[32m     29\u001b[39m         \u001b[38;5;66;03m#print(checkpoint) #debug\u001b[39;00m\n\u001b[32m     30\u001b[39m         llm_structured_output = \u001b[38;5;28mself\u001b[39m.get_structured_output_from_llm(\u001b[38;5;28mself\u001b[39m.system_message, messages) \u001b[38;5;66;03m#pass to llm, get responses\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mBatchProcess.prepare_llm_inputs\u001b[39m\u001b[34m(self, df, checkpoint, batch_size)\u001b[39m\n\u001b[32m     55\u001b[39m counter = \u001b[32m1\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(checkpoint, checkpoint+batch_size):\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m     job_id = \u001b[38;5;28mint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mjob_id\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     58\u001b[39m     raw_jd = df.iloc[i][\u001b[33m'\u001b[39m\u001b[33mdescription\u001b[39m\u001b[33m'\u001b[39m].strip()\n\u001b[32m     59\u001b[39m     job_ids.append(job_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\job_posting_salary_prediction\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\job_posting_salary_prediction\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1752\u001b[39m, in \u001b[36m_iLocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot index by location index with a non-integer key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1751\u001b[39m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1752\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1754\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._ixs(key, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\job_posting_salary_prediction\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1685\u001b[39m, in \u001b[36m_iLocIndexer._validate_integer\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1683\u001b[39m len_axis = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.obj._get_axis(axis))\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key >= len_axis \u001b[38;5;129;01mor\u001b[39;00m key < -len_axis:\n\u001b[32m-> \u001b[39m\u001b[32m1685\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msingle positional indexer is out-of-bounds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    batch_process.process(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "440"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_process.start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "def validate_files():\n",
    "    json_files = glob.glob(\"extracted_jds/*\")\n",
    "    # Iterate over each file and read the data\n",
    "    for file in json_files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)  # Load the data from each JSON file\n",
    "            rand_idx = random.randint(0,len(data)-1)\n",
    "            rand_job_id = data[rand_idx]['job_id']\n",
    "            match = re.search(r\"batch_\\d+_row_(\\d+)_extracted_jd\\.json\", file)\n",
    "            first_row_idx = int(match.group(1)) - (len(data)-1)\n",
    "            correct_row_no = first_row_idx +  rand_idx \n",
    "            correct_job_id = sampled_df.iloc[correct_row_no]['job_id'] \n",
    "            if correct_job_id != rand_job_id:\n",
    "                raise Exception(f\"row {correct_row_no} dont match, correct id: {correct_job_id}, wrong id:{rand_job_id}, filename:{file}\")\n",
    "\n",
    "for i in range(50):\n",
    "    validate_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "def combine(filename):\n",
    "    combined = []\n",
    "    # Find all JSON files in a directory\n",
    "    json_files = glob.glob(\"extracted_jds/*\")\n",
    "    # Iterate over each file and read the data\n",
    "    for file in json_files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)  # Load the data from each JSON file\n",
    "            combined.extend(data)\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(combined, f, indent=4) \n",
    "\n",
    "combine(\"gpt_extracted_jds.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the GPT extracted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"gpt_extracted_jds.json\", \"r\") as f:\n",
    "    gpt_data = json.load(f)  # Load JSON into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data = pd.DataFrame(gpt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_data = gpt_data.rename(columns={'Compensation_and_Benefits': 'gpt_Compensation_and_Benefits','Preferred_Qualifications':'gpt_Preferred_Qualifications','Experience_Level':'gpt_Experience_Level','Educational_Requirements':'gpt_Educational_Requirements','Required_Skills':'gpt_Required_Skills'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt_Required_Skills</th>\n",
       "      <th>gpt_Educational_Requirements</th>\n",
       "      <th>gpt_Experience_Level</th>\n",
       "      <th>gpt_Preferred_Qualifications</th>\n",
       "      <th>gpt_Compensation_and_Benefits</th>\n",
       "      <th>job_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Customer service orientation, time management,...</td>\n",
       "      <td>Property &amp; casualty license required; no addit...</td>\n",
       "      <td>3 years</td>\n",
       "      <td>Experience managing a commercial book valued b...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>3905335633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 gpt_Required_Skills  \\\n",
       "0  Customer service orientation, time management,...   \n",
       "\n",
       "                        gpt_Educational_Requirements gpt_Experience_Level  \\\n",
       "0  Property & casualty license required; no addit...              3 years   \n",
       "\n",
       "                        gpt_Preferred_Qualifications  \\\n",
       "0  Experience managing a commercial book valued b...   \n",
       "\n",
       "  gpt_Compensation_and_Benefits      job_id  \n",
       "0                           N/A  3905335633  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine gemini and gpt dataframes on the same job id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>description</th>\n",
       "      <th>Required_Skills</th>\n",
       "      <th>Educational_Requirements</th>\n",
       "      <th>Experience_Level</th>\n",
       "      <th>Preferred_Qualifications</th>\n",
       "      <th>Compensation_and_Benefits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>921716</td>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "      <td>Proficiency in Adobe Creative Cloud and Micros...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1-2 years of marketing and graphic design expe...</td>\n",
       "      <td>Proficiency in Adobe Creative Cloud (Indesign,...</td>\n",
       "      <td>$18-20/hour, paid time off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id                                        description  \\\n",
       "0  921716  Job descriptionA leading real estate firm in N...   \n",
       "\n",
       "                                     Required_Skills Educational_Requirements  \\\n",
       "0  Proficiency in Adobe Creative Cloud and Micros...                      N/A   \n",
       "\n",
       "                                    Experience_Level  \\\n",
       "0  1-2 years of marketing and graphic design expe...   \n",
       "\n",
       "                            Preferred_Qualifications  \\\n",
       "0  Proficiency in Adobe Creative Cloud (Indesign,...   \n",
       "\n",
       "    Compensation_and_Benefits  \n",
       "0  $18-20/hour, paid time off  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = new_df.rename(columns={'Compensation_and_Benefits': 'gemini_Compensation_and_Benefits','Preferred_Qualifications':'gemini_Preferred_Qualifications','Experience_Level':'gemini_Experience_Level','Educational_Requirements':'gemini_Educational_Requirements','Required_Skills':'gemini_Required_Skills'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>gemini_Required_Skills</th>\n",
       "      <th>gemini_Educational_Requirements</th>\n",
       "      <th>gemini_Experience_Level</th>\n",
       "      <th>gemini_Preferred_Qualifications</th>\n",
       "      <th>gemini_Compensation_and_Benefits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>921716</th>\n",
       "      <td>Job descriptionA leading real estate firm in N...</td>\n",
       "      <td>Proficiency in Adobe Creative Cloud and Micros...</td>\n",
       "      <td>N/A</td>\n",
       "      <td>1-2 years of marketing and graphic design expe...</td>\n",
       "      <td>Proficiency in Adobe Creative Cloud (Indesign,...</td>\n",
       "      <td>$18-20/hour, paid time off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              description  \\\n",
       "job_id                                                      \n",
       "921716  Job descriptionA leading real estate firm in N...   \n",
       "\n",
       "                                   gemini_Required_Skills  \\\n",
       "job_id                                                      \n",
       "921716  Proficiency in Adobe Creative Cloud and Micros...   \n",
       "\n",
       "       gemini_Educational_Requirements  \\\n",
       "job_id                                   \n",
       "921716                             N/A   \n",
       "\n",
       "                                  gemini_Experience_Level  \\\n",
       "job_id                                                      \n",
       "921716  1-2 years of marketing and graphic design expe...   \n",
       "\n",
       "                          gemini_Preferred_Qualifications  \\\n",
       "job_id                                                      \n",
       "921716  Proficiency in Adobe Creative Cloud (Indesign,...   \n",
       "\n",
       "       gemini_Compensation_and_Benefits  \n",
       "job_id                                   \n",
       "921716       $18-20/hour, paid time off  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt_data.set_index(\"job_id\", inplace=True)\n",
    "#sampled_df.set_index(\"job_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = sampled_df.join(gpt_data, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_id', 'description', 'gemini_Required_Skills',\n",
       "       'gemini_Educational_Requirements', 'gemini_Experience_Level',\n",
       "       'gemini_Preferred_Qualifications', 'gemini_Compensation_and_Benefits',\n",
       "       'gpt_Required_Skills', 'gpt_Educational_Requirements',\n",
       "       'gpt_Experience_Level', 'gpt_Preferred_Qualifications',\n",
       "       'gpt_Compensation_and_Benefits'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save combined outputs to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv('merged_gpt_gemini_jd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare gpt and gemini outputs using rouge score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading builder script: 100%|██████████| 6.27k/6.27k [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import evaluate, rouge_score\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "rouge_scores = {'job_id':[], 'description':[], 'gpt_extract':[], 'gemini_extract':[], 'rouge_score':[]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:44<00:00,  6.07it/s]\n"
     ]
    }
   ],
   "source": [
    "for row in tqdm(merged_df.itertuples(index=True), total=len(merged_df)):\n",
    "    gpt = f\"\"\"\n",
    "{row.gpt_Required_Skills}\n",
    "{row.gpt_Educational_Requirements}\n",
    "{row.gpt_Experience_Level}\n",
    "{row.gpt_Preferred_Qualifications}\n",
    "{row.gpt_Compensation_and_Benefits}\n",
    "\"\"\"\n",
    "    gemini = f\"\"\"\n",
    "{row.gemini_Required_Skills}\n",
    "{row.gemini_Educational_Requirements}\n",
    "{row.gemini_Experience_Level}\n",
    "{row.gemini_Preferred_Qualifications}\n",
    "{row.gemini_Compensation_and_Benefits}\n",
    "\"\"\"\n",
    "    r_score = rouge.compute(predictions=[gpt],references=[gemini])\n",
    "    rouge_scores['job_id'].append(row.job_id)\n",
    "    rouge_scores['description'].append(row.description)\n",
    "    rouge_scores['gpt_extract'].append(gpt)\n",
    "    rouge_scores['gemini_extract'].append(gemini)\n",
    "    rouge_scores['rouge_score'].append(r_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores_df = pd.DataFrame(rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.6329113924050633,\n",
       " 'rouge2': 0.3116883116883117,\n",
       " 'rougeL': 0.45569620253164556,\n",
       " 'rougeLsum': 0.6075949367088608}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores_df['rouge_score'][700]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores_df.to_csv(\"rouge_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores_df.to_json('rouge_scores.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
